[{"content":"WindTerm WindTerm是新一代开源的免费终端工具，支持Windos、Linux和macOS，可以直接在release里面找对应版本下载.\n功能介绍 使用最多的就是远程连接服务器，整体界面上包含连接的会话、会话分组、会话文件管理器、命令历史记录及各种资源的管理器，其同样能查看当前会话的内存资源占用，以及命令提示。\n使用方法 最多的使用是SSH，比如使用这个工具我远程连接多个服务器，就比开好几个终端界面要操作的舒服一些，终端界面我更倾向于2~3个窗口来处理个某个项目，如果要连接公司的测试服务器或者远程操作就比较方便。\n文件管理器，我们可以直接上传文件，只需要把本地的文件拖动过去即可。如果是SSH窗口上传，需要安装lrzsz。另外也支持高速传输模式。\n需要注意的是WindTerm会自动锁屏，超过默认30分钟就会锁屏，Windows可以直接改，Mac需要找到user.config文件，删除application.fingerprint和application.masterPassword，再找到.wind/profiles/default.v10/terminal/user.sessions文件删除session.autoLogin，主密码就变成空字符串。\n","date":"2022-11-17T00:00:00Z","image":"https://zonzeeli.github.io/p/windterm/windterm_hua1c4b0f4a546cd5b0d43dc2a874d419d_881168_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/windterm/","title":"WindTerm 使用介绍"},{"content":"Windows Terminal 作为微软官方为大家提供的终端软件，Windows Terminal具备非常简约且符合windows风格的界面，对于个人开发者来说是比较方便的工具，但是其因为没有太多设置，都是微软官方提供的比较简单的配置，我们需要下载额外的工具来完善。\n提示引擎 Oh My Posh是配置Windos Terminal的主要工具，其不仅支持windows，同时使用linux和macos。安装方法如下：\n1  winget install JanDeDobbeleer.OhMyPosh -s winget   或者用scoop直接从github上拉取下载\n1  scoop install https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest/download/oh-my-posh.json   提示 在安装好Oh My Posh后，打开PowerShell，按照如下运行：\n1  notepad $PROFILE   如果没有该文件，可以直接创建，\n1  New-Item -Path $PROFILE -Type File -Force   然后添加这行，\n1  oh-my-posh init pwsh | Invoke-Expression   另外我们可以选择自己想要的主题，可以通过如下命令将所有主题展示出来：\n1  Get-PoshThemes   找到一个你喜欢用的主题，然后去User/AppData里找到该路径，\n1  C:\\Users\\xxxx\\AppData\\Local\\Programs\\oh-my-posh\\themes\\xxxx.omp.json   然后将上面的改为如下命令就可以应用主题了。\n1  oh-my-posh init pwsh --config C:\\Users\\xxxx\\AppData\\Local\\Programs\\oh-my-posh\\themes\\xxxx.omp.json | Invoke-Expression   字体 官方推荐的Nerd字体，官方提供的字体不多，同样这个网站中提供了终端icon的列表。具体的安装方式可以直接下载，然后拖到本地字体文件夹中安装，也可以使用我们下面说的工具来下载。\n1  oh-my-posh font install   选择喜欢的字体下载即可，如果安装了Nerd Font，Windows Terminal需要配置一下（如果是Oh My Posh安装的不需要设置），打开setting中的settings.json，快捷键是CTRL + SHIFT + ,，在profiles的default中添加font.face\n1 2 3 4 5 6 7 8 9 10 11 12  { \u0026#34;profiles\u0026#34;: { \u0026#34;defaults\u0026#34;: { \u0026#34;font\u0026#34;: { \u0026#34;face\u0026#34;: \u0026#34;MesloLGM NF\u0026#34; } } } }   定制启动界面 如果想要删除启动界面的那些文字，我们在启动PowerShell时要加上-NoLogo，在Setting-Profiles-Windos PowerShell-Command line启动后添加。\n如果想要自定义的话，则打开PowerShell的配置文件，\n1  notepad $PROFILE   在最上面添加一下内容即可。\n1 2 3 4 5 6  clear $hello=\u0026#34; 定制你自己的内容 \u0026#34; $hello \u0026#34;定制你自己的内容\u0026#34;   添加icon 这里使用的也是官方推荐的Terminal-Icons，输入以下命令，\n1  Install-Module -Name Terminal-Icons -Repository PSGallery   然后同样进入PowerShell的配置文件，输入notepad $PROFILE，在下面添加如下命令就可以显示出图标。\n1  Import-Module Terminal-Icons   添加Posh-git 如果想要将Git和PowerShell整合在一起，即可以查看分支和提交记录等，安装如下模块，\n1  Install-Module posh-git -Scope CurrentUser   然后继续在PowerShell的配置文件，输入notepad $PROFILE，在下面添加如下命令，\n1  Import-Module posh-git   ","date":"2022-10-26T00:00:00Z","image":"https://zonzeeli.github.io/p/windows-terminal/windowsterminal_hu13ca29e15472f42773d7e958e37ce140_1543094_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/windows-terminal/","title":"Windows Terminal使用及配置教程"},{"content":"HTTP Rule gRPC Transcoding 是一种用于在 gRPC 方法和一个或多个 HTTP REST 端点之间进行映射的功能。它允许开发人员构建一个同时支持 gRPC API 和 REST API 的 API 服务。HttpRule 定义 gRPC/REST 映射的模式。映射指定 gRPC 请求消息的不同部分如何映射到 URL 路径、URL 查询参数和 HTTP 请求正文。它还控制 gRPC 响应消息如何映射到 HTTP 响应正文。HttpRule 通常被指定为 google.api.http gRPC 方法的注解。\n每个映射指定一个 URL 路径模板和一个 HTTP 方法。路径模板可以引用 gRPC 请求消息中的一个或多个字段，只要每个字段是原始（非消息）类型的非重复字段即可。路径模板控制请求消息的字段如何映射到 URL 路径。\n例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13  service Messaging { rpc GetMessage(GetMessageRequest) returns (Message) { option (google.api.http) = { get: \u0026#34;/v1/{name=messages/*}\u0026#34; }; }}message GetMessageRequest { string name = 1; // Mapped to URL path. }message Message { string text = 1; // The resource content. }  这启用了 HTTP REST 到 gRPC 的映射，如下：\n   HTTP gRPC     GET /v1/messages/123456 GetMessage(name: \u0026ldquo;messages/123456\u0026rdquo;)    如果没有 HTTP 请求 body，则请求消息中没有被路径模板绑定的任何字段都会自动成为 HTTP query parameters。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  service Messaging { rpc GetMessage(GetMessageRequest) returns (Message) { option (google.api.http) = { get:\u0026#34;/v1/messages/{message_id}\u0026#34; }; }}message GetMessageRequest { message SubMessage { string subfield = 1; } string message_id = 1; // Mapped to URL path.  int64 revision = 2; // Mapped to URL query parameter `revision`.  SubMessage sub = 3; // Mapped to URL query parameter `sub.subfield`. }  这启用了 HTTP JSON 到 RPC 映射，如下：\n   HTTP gRPC     GET /v1/messages/123456?revision=2\u0026amp;sub.subfield=foo GetMessage(message_id: \u0026ldquo;123456\u0026rdquo; revision: 2 sub: SubMessage(subfield: \u0026ldquo;foo\u0026rdquo;))    这里需要注意的是，映射到 URL 查询参数的字段必须具有原始类型或重复的原始类型或非重复的消息类型。在 repeated 类型的情况下，参数可以在 URL 中重复为...?param=A\u0026amp;param=B. 在 message 类型的情况下，消息的每个字段都映射到一个单独的参数，例如...?foo.a=A\u0026amp;foo.b=B\u0026amp;foo.c=C。\n对于可以添加 body 的 HTTP 方法，body 字段指定映射。比如 message 集合上的 REST update 方法：\n1 2 3 4 5 6 7 8 9 10 11 12  service Messaging { rpc UpdateMessage(UpdateMessageRequest) returns (Message) { option (google.api.http) = { patch: \u0026#34;/v1/messages/{message_id}\u0026#34; body: \u0026#34;message\u0026#34; }; }}message UpdateMessageRequest { string message_id = 1; // mapped to the URL  Message message = 2; // mapped to the body }  启用了以下 HTTP JSON 到 RPC 映射，其中请求正文中 JSON 的表示由 protos JSON 编码确定：\n   HTTP gRPC     PATCH /v1/messages/123456 { \u0026ldquo;text\u0026rdquo;: \u0026ldquo;Hi!\u0026rdquo; } UpdateMessage(message_id: \u0026ldquo;123456\u0026rdquo; message { text: \u0026ldquo;Hi!\u0026rdquo; })    可以在 body 映射中使用*来表示所有不受路径模板绑定的字段都应该映射到 body中。比如：\n1 2 3 4 5 6 7 8 9 10 11 12  service Messaging { rpc UpdateMessage(Message) returns (Message) { option (google.api.http) = { patch: \u0026#34;/v1/messages/{message_id}\u0026#34; body: \u0026#34;*\u0026#34; }; }}message Message { string message_id = 1; string text = 2;}  启用了 HTTP JSON 到 RPC 映射，如下：\n   HTTP gRPC     PATCH /v1/messages/123456 { \u0026ldquo;text\u0026rdquo;: \u0026ldquo;Hi!\u0026rdquo; } UpdateMessage(message_id: \u0026ldquo;123456\u0026rdquo; text: \u0026ldquo;Hi!\u0026quot;)    请注意，在正文映射中使用*时，不可能有 HTTP 参数，因为所有不受路径绑定的字段都以正文结尾。 这使得该选项在定义 REST API 时很少在实践中使用。*的常见用法是在根本不使用 URL 来传输数据的自定义方法中。\n可以使用该additional_bindings选项为一个 RPC 定义多个 HTTP 方法。例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  service Messaging { rpc GetMessage(GetMessageRequest) returns (Message) { option (google.api.http) = { get: \u0026#34;/v1/messages/{message_id}\u0026#34; additional_bindings { get: \u0026#34;/v1/users/{user_id}/messages/{message_id}\u0026#34; } }; }}message GetMessageRequest { string message_id = 1; string user_id = 2;}  启用了两种可选的 HTTP JSON 到 RPC 映射，如下：\n   HTTP gRPC     GET /v1/messages/123456 GetMessage(message_id: \u0026ldquo;123456\u0026rdquo;)   GET /v1/users/me/messages/123456 GetMessage(user_id: \u0026ldquo;me\u0026rdquo; message_id: \u0026ldquo;123456\u0026rdquo;)    接下来介绍 HTTP 的映射规则：\n 请求字段（请求消息中的递归扩展嵌套消息）分为以下三类：   路径模板引用的字段。它们通过 URL 路径传递。 引用的字段HttpRule.body。它们通过 HTTP 请求正文传递。 所有其他字段都是通过 URL 查询参数传递的，参数名称是请求消息中的字段路径。一个重复的字段可以表示为同名的多个查询参数。  如果HttpRule.body为*，则没有 URL 查询参数，所有字段都通过 URL 路径和 HTTP 请求正文传递。 如果HttpRule.body省略，则没有 HTTP 请求正文，所有字段都通过 URL 路径和 URL 查询参数传递。  ","date":"2022-08-17T00:00:00Z","image":"https://zonzeeli.github.io/p/httprule/grpcgooleapi_hu76928c90444e9d8bd04a53b1f2bdf9cc_731648_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/httprule/","title":"gRPC-google.api的HttpRule介绍"},{"content":"前言  这篇文章主要整合了 Go 语言的一些内存管理的知识，只是浅显笼统概括，并且用一些面试题来总结。\n注：以下内容和图片基本来自公众号：网管叨bi叨，一个我经常看的博主，推荐关注。\n内存对齐  我们编程的任何一个变量在内存中存放都按照一定的规则，这里主要介绍的就是内存对齐的规则，下面为简单概括，详情见文章Go语言——内存对齐\n 理论上计算机可以访问任意地址的变量，但是在访问特定类型通常在特定的内存地址中，数据存放并不是随意存放，是有规则的顺序，我们能够分析出，内存对齐是为了能够快速访问内存进行数据的存取，但是会消耗内存空间，用空间换时间的一种内存存储规则。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  func main() { s1 := []string{\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;} s2 := []string{\u0026#34;1\u0026#34;} fmt.Println(unsafe.Sizeof(s1)) // 24 \tfmt.Println(unsafe.Sizeof(s2)) // 24  type t1 struct { a int32 b int64 c int32 } type t2 struct { a int32 b int32 c int64 } fmt.Println(unsafe.Sizeof(t1{})) // 24 \tfmt.Println(unsafe.Sizeof(t2{})) // 16 }    是不是对这个结果有疑问呢？为什么s1和s2的数据长度不同，但是打印出的内存长度一样？为什么t1和t2的结构体只是定义的顺序不同，内存长度却不一样？\n 这里要说明一下，go语言通过unsafe.Sizeof(x)打印的变量占用的内存字节数，和底层数据无关，不包含x所指向的内容大小，所以第一个疑问解决了。也同理我们可以通过unsafe.Sizeof()打印出各个类型的内存占用大小。\n 注：这里使用的是64位系统。\n   类型 字节数     bool 1   intN, uintN, floatN, complexN N/8 个字节 （int32 是 4 个字节）   int, uint, uintptr 计算机字长/8 (64位 是 8 个字节)   *T, map, func, chan 计算机字长/8 (64位 是 8 个字节)   string （data、len） 2 * 计算机字长/8 (64位 是 16 个字节)   interface (tab、data 或 _type、data) 2 * 计算机字长/8 (64位 是 16 个字节)   []T (array、len、cap) 3 * 计算机字长/8 (64位 是 24 个字节)    1 2 3 4 5  type t struct { a bool // 1个字节  b int // 8个字节  c string // 16个字节 }    对于上面的结构，如果是没有进行过内存对齐，则按照存放的顺序，以64位系统的每8个字节取数据的规则，会发现除了a，b和c都不是从头取的，过程如图：\n 这里就有一个问题，对于b和c没有做到从起始位开始取数据，所以会造成之后在再次拼接整理的操作，需要多次内存访问和整理的步骤。而如果经过内存对齐，就会如图：\n 所以我们能发现，内存对齐减少了操作步骤，但是却浪费了内存空间占用的资源。\n内存对齐规则  成员对齐规则：针对一个基础类型变量，如果unsafe.AlignOf()返回的值是m，那么该变量的地址需要被m整除（如果当前地址不能整除，填充空白字节，直至可以整除）。 整体对齐规则：针对一个结构体，如果unsafe.AlignOf()返回值是m，需要保证该结构体整体内存占用是m的整数倍，如果当前不是整数倍，需要在后面填充空白字节。   针对该规则，我们再把上述的结构体和unsafe.Offsetof()拿出来分析一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  func main() { type t1 struct { a int32 // 4个字节 \tb int64 // 8个字节 \tc float32 // 4个字节 \td bool // 1个字节 \t} t := t1{} fmt.Println(unsafe.Offsetof(t.a)) // 0 \tfmt.Println(unsafe.Offsetof(t.b)) // 8 \tfmt.Println(unsafe.Offsetof(t.c)) // 16 \tfmt.Println(unsafe.Offsetof(t.d)) // 20 \tfmt.Println(unsafe.Alignof(t)) // 8 \tfmt.Println(unsafe.Sizeof(t)) // 24 \t// 假设从地址0开始 \t// unsafe.Sizeof(int32(1)) = 4，unsafe.Alignof(int32(1)) = 4，地址0开始，可以被4整除 \t// unsafe.Sizeof(int64(1)) = 8，unsafe.Alignof(int64(1)) = 8，地址需要从8开始，才可以被8整除，[4,8]的位置用0来补充 \t// unsafe.Sizeof(float32(1)) = 4，unsafe.Alignof(float32(1)) = 4，地址需要从16开始，可以被4整除，[8,16]的位置被t.b占满 \t// unsafe.Sizeof(true) = 1, unsafe.Alignof(true) = 1, 地址从20开始即可，[16,20]的位置被c沾满。 \t// 由于结构体也需要对齐，要被8整除，所以要补0到24。 }   内存分配 知道了内存存放的规则后，那么我们应该清楚是计算机是如何给程序分配内存的。\n Golang运行时的内存分配算法主要源自 Google 为 C 语言开发的TCMalloc算法，全称Thread-Caching Malloc。核心思想就是把内存分为多级管理，从而降低锁的粒度。它将可用的堆内存采用二级分配的方式进行管理：每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。\n 在Go里面有两种内存分配策略，一种适用于程序里小内存块的申请，另一种适用于大内存块的申请，大内存块指的是大于32KB。\n基础概念 mspan：Go中内存管理的基本单元，是由一片连续的8KB的页组成的大块内存。注意，这里的页和操作系统本身的页并不是一回事，它一般是操作系统页大小的几倍。一句话概括：mspan是一个包含起始地址、mspan规格、页的数量等内容的双端链表。每个mspan按照它自身的属性Size Class的大小分割成若干个object，每个object可存储一个对象。\nmcache：每个工作线程都会绑定一个mcache，本地缓存可用的mspan资源，这样就可以直接给Goroutine分配，因为不存在多个Goroutine竞争的情况，所以不会消耗锁资源。\nmcentral：为所有mcache提供切分好的mspan资源。每个central保存一种特定大小的全局mspan列表，包括已分配出去的和未分配出去的。 每个mcentral对应一种mspan，而mspan的种类导致它分割的object大小不同。当工作线程的mcache中没有合适（也就是特定大小的）的mspan时就会从mcentral获取。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  //path: /usr/local/go/src/runtime/mcentral.go  type mcentral struct { // 互斥锁  lock mutex // 规格  sizeclass int32 // 尚有空闲object的mspan链表  nonempty mSpanList // 没有空闲object的mspan链表，或者是已被mcache取走的msapn链表  empty mSpanList // 已累计分配的对象个数  nmalloc uint64 }   mheap：代表Go程序持有的所有堆空间，Go程序使用一个mheap的全局对象_mheap来管理堆内存。\n 当mcentral没有空闲的mspan时，会向mheap申请。而mheap没有资源时，会向操作系统申请新内存。mheap主要用于大对象的内存分配，以及管理未切割的mspan，用于给mcentral切割成小对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  package main type smallStruct struct { a, b int64 c, d float64 } func main() { smallAllocation() } //go:noinline func smallAllocation() *smallStruct { return \u0026amp;smallStruct{} }   小于 32 KB 内存块的分配策略  当程序里发生了32kb以下的小块内存申请时，Go会从一个叫做的 mcache 的本地缓存给程序分配内存。这个本地缓存 mcache 持有一系列的大小为 32kb 的内存块，这样的一个内存块里叫做 mspan，它是要给程序分配内存时的分配单元。\n 在 Go 的调度器模型里，每个线程M会绑定给一个处理器P，在单一粒度的时间里只能做多处理运行一个goroutine，每个P都会绑定一个上面说的本地缓存mcache。当需要进行内存分配时，当前运行的goroutine会从mcache中查找可用的mspan。从本地mcache里分配内存时不需要加锁，这种分配策略效率更高。\n 但是有的变量很小就是数字，有的却是一个复杂的结构体，申请内存时都分给他们一个mspan这样的单元会不会产生浪费。其实mcache持有的这一系列的mspan并不都是统一大小的，而是按照大小，从8字节到32KB分了67类的msapn。\n 结构体刚好是32字节，所以直接分配到其中一个，但是如果mcachce里没有空闲的32字节的mspan了该怎么办？Go里还为每种类别的mspan维护着一个mcentral。\n 刚才说过mcentral的作用是为所有mcache提供切分好的mspan资源。每个central会持有一种特定大小的全局mspan列表，包括已分配出去的和未分配出去的。 每个mcentral对应一种mspan，当工作线程的mcache中没有合适（也就是特定大小的）的mspan时就会从mcentral 去获取。mcentral被所有的工作线程共同享有，存在多个goroutine竞争的情况，因此从mcentral获取资源时需要加锁。\n mcentral里维护着两个双向链表，nonempty表示链表里还有空闲的mspan待分配。empty表示这条链表里的mspan都被分配了object。\nmcache从mcentral获取和归还mspan的流程：\n 获取 加锁；从nonempty链表找到一个可用的mspan；并将其从nonempty链表删除；将取出的mspan加入到empty链表；将mspan返回给工作线程；解锁。 归还 加锁；将mspan从empty链表删除；将mspan加入到nonempty链表；解锁。  当mcentral没有空闲的mspan时，会向mheap申请。而mheap没有资源时，会向操作系统申请新内存。mheap主要用于大对象的内存分配，以及管理未切割的mspan，用于给mcentral切割成小对象。mheap中含有所有规格的mcentral，所以，当一个mcache从mcentral申请mspan时，只需要在独立的mcentral中使用锁，并不会影响申请其他规格的mspan。\nmheap里的arena 区域是真正的堆区，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象。\n大于 32 KB 内存块的内存分配  Go没法使用工作线程的本地缓存mcache和全局中心缓存mcentral上管理超过32KB的内存分配，所以对于那些超过32KB的内存申请，会直接从堆上(mheap)上分配对应的数量的内存页（每页大小是8KB）给程序。\n逃逸分析  通常情况下，编译器是倾向于将变量分配到栈上的，因为它的开销小，最极端的就是\u0026quot;zero garbage\u0026quot;，所有的变量都会在栈上分配，这样就不会存在内存碎片，垃圾回收之类的东西。变量是在栈上分配还是在堆上分配，是由逃逸分析的结果决定的。\nGo 官方上有这么一段内存逃逸分析的QA\nQ：如何得知变量是分配在栈（stack）上还是堆（heap）上？\nA: 准确地说，你并不需要知道。Golang 中的变量只要被引用就一直会存活，存储在堆上还是栈上由内部实现决定而和具体的语法没有关系。知道变量的存储位置确实对程序的效率有帮助。如果可能，Golang 编译器会将函数的局部变量分配到函数栈帧（stack frame）上。然而，如果编译器不能确保变量在函数 return 之后不再被引用，编译器就会将变量分配到堆上。而且，如果一个局部变量非常大，那么它也应该被分配到堆上而不是栈上。当前情况下，如果一个变量被取地址，那么它就有可能被分配到堆上。然而，还要对这些变量做逃逸分析，如果函数 return 之后，变量不再被引用，则将其分配到栈上。\n Go编译器会跨越函数和包的边界进行全局的逃逸分析。它会检查是否需要在堆上为一个变量分配内存，还是说可以在栈本身的内存里对其进行管理。\n1 2 3 4 5 6 7 8 9 10 11 12  package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Called heapAnalysis\u0026#34;, heapAnalysis()) } //go:noinline func heapAnalysis() *int { data := 55 return \u0026amp;data }   1 2 3 4 5 6 7  go build -gcflags \u0026#34;-m -l\u0026#34; ./scratch.go:9:9: \u0026amp;data escapes to heap ./scratch.go:8:2: moved to heap: data ./scratch.go:4:14: \u0026#34;Called heapAnalysis\u0026#34; escapes to heap ./scratch.go:4:49: heapAnalysis() escapes to heap ./scratch.go:4:13: main ... argument does not escape   main和heapAnalysis函数分配在一个栈上。由于函数具有自己的变量，因此也会将变量分配到栈的某个地方。但是编译器检查到该值是返回了它的指针，并且已用于另一个函数，因此变量被移到了堆中，主函数会从堆中访问该变量。\n有个特殊说明，\n1 2 3 4 5 6 7 8 9 10 11 12  package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Called stackAnalysis\u0026#34;, stackAnalysis()) } //go:noinline (加一行特殊的注释让编译器不对函数进行内联，内联是一种手动或编译器优化，用于将简短函数的调用替换为函数体本身。这么做的原因是它可以消除函数调用本身的开销，也使得编译器能更高效地执行其他的优化策略) func stackAnalysis() int { data := 55 return data }   1 2 3 4 5  go build -gcflags \u0026#34;-m -l\u0026#34; ./scratch.go:4:14: \u0026#34;Called stackAnalysis\u0026#34; escapes to heap ./scratch.go:4:51: stackAnalysis() escapes to heap ./scratch.go:4:13: main ... argument does not escape   第4行14个字符处的字符串标量\u0026quot;Called stackAnalysis\u0026quot;逃逸到堆上。\n第4行51个字符串的函数调用stackAnalysis()逃逸到了堆上。\nescapes to heap\u0026quot;的意思是变量需要在函数栈之间共享，上面的例子就是在main和fmt.Println之间共享。main和stackAnalysis函数分配在一个栈上。由于函数具有自己的变量，因此也会将变量分配到栈的某个地方。当函数返回时，与该函数关联的所有变量也会从内存中删除。这里并没有逃逸到堆上，而是在栈上。这里是因为fmt.Print系列的函数问题，变量逃逸了，如果是print，会打印的是does not escape。\n垃圾回收  内存分配了之后要回收，这就需要 GC。什么是 GC？PHP、Java 和 Go 等语言使用自动的内存管理系统，有内存分配器和垃圾收集器来代为分配和回收内存，其中垃圾收集器就是我们常说的GC。\n 主要原因是栈是一块专用内存，专门为了函数执行而准备的，存储着函数中的局部变量以及调用栈。除此以外，栈中的数据都有一个特点——简单。比如局部变量不能被函数外访问，所以这块内存用完就可以直接释放。正是因为这个特点，栈中的数据可以通过简单的编译器指令自动清理，并不需要通过 GC 来回收。\n Go的垃圾收集器从一开始到现在一直在演进，在v1.5版本开始三色标记法作为垃圾回收算法前使用Mark-And-Sweep（标记清除）算法。从v1.5版本Go实现了基于三色标记清除的并发垃圾收集器，大幅度降低垃圾收集的延迟从几百 ms 降低至 10ms 以下。在v1.8又使用混合写屏障将垃圾收集的时间缩短至 0.5ms 以内。\n三色标记法 三色标记算法将程序中的对象分成白色、黑色和灰色三类：\n 白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收； 黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象，垃圾回收器不会扫描这些对象的子对象； 灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；  第一步：在进入GC的三色标记阶段的一开始，所有对象都是白色的。\n第二步, 遍历根节点集合里的所有根对象，把根对象引用的对象标记为灰色，从白色集合放入灰色集合。\n第三步, 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合\n第四步：重复第三步, 直到灰色集合中无任何对象。\n第五步：回收白色集合里的所有对象，本次垃圾回收结束。\n写屏障  Go 在GC阶段执行三色标记前，还需要先做一个准备工作——打开写屏障(Write Barrier)。那么写屏障是什么呢？我们知道三色标记法是一种可以并发执行的算法。所以在GC运行过程中程序的函数栈内可能会有新分配的对象，那么这些对象该怎么通知到 GC，怎么给他们着色呢？如果还是按照之前新建的对象标记为白色就有可能出现下图中的问题：\n 在 GC 进行的过程中，应用程序新建了对象 I，此时如果已经标记成黑的对象F引用了对象 I，那么在本次 GC 执行过程中因为黑色对象不会再次扫描，所以如果I着色成白色的话，会被回收掉，这显然是不允许的。\n 这个时候就需要我们的写屏障出马了。写屏障主要做一件事情，修改原先的写逻辑，然后在对象新增的同时给它着色，并且着色为灰色。因此打开了写屏障可以保证了三色标记法在并发下安全正确地运行。那么有人就会问这些写屏障标记成灰色的对象什么时候回收呢？答案是后续的 GC 过程中回收，在新的 GC 过程中所有已存对象就又从白色开始逐步被标记啦。\n三色不变性  想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的任意一种：\n 强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象； 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径  屏障技术  垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。\nGo 的混合写屏障  在Go 语言 v1.7 版本之前，使用的是Dijkstra插入写屏障保证强三色不变性，但是运行时并没有在所有的垃圾收集根对象上开启插入写屏障。因为 Go 语言的应用程序可能包含成百上千的 goroutine，而垃圾收集的根对象一般包括全局变量和栈对象，如果运行时需要在几百个 goroutine 的栈上都开启写屏障，会带来巨大的额外开销，所以 Go 团队在实现上选择了在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描，在活跃 goroutine 非常多的程序中，重新扫描的过程需要占用 10 ~ 100ms 的时间。\nGo 语言在 v1.8 组合 Dijkstra 插入写屏障和 Yuasa 删除写屏障构成了如下所示的混合写屏障，该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色：\n1 2 3 4 5  writePointer(slot, ptr): shade(*slot) if current stack is grey: shade(ptr) *slot = ptr    为了移除栈的重扫描过程，除了引入混合写屏障之外，在垃圾收集的标记阶段，我们还需要将创建的所有新对象都标记成黑色，防止新分配的栈内存和堆内存中的对象被错误地回收，因为栈内存在标记阶段最终都会变为黑色，所以不再需要重新扫描栈空间。\n一次完整的GC过程  Go的垃圾回收器在使用了三色标记清除算法和混合写屏障后大大减少了暂停程序（STW）的时间，主要是在开启写屏障前和移除写屏障前暂停应用程序。\n Go的垃圾收集的整个过程可以分成标记准备、标记、标记终止和清除四个不同阶段，每个阶段完成的工作如下：\n标记准备阶段  暂停程序，所有的处理器在这时会进入安全点（Safe point）\n标记阶段  将状态切换至 _GCmark、开启写屏障、用户程序协助（Mutator Assiste）并将根对象入队； 恢复执行程序，标记进程和用于协助的用户程序会开始并发标记内存中的对象，标记用的算法就是上面介绍的三色标记清除法。写屏障会将被覆盖的指针和新指针都标记成灰色，而所有新创建的对象都会被直接标记成黑色； 开始扫描根对象，包括所有 goroutine 的栈、全局对象以及不在堆中的运行时数据结构，扫描 goroutine 栈期间会暂停当前处理器； 依次处理灰色队列中的对象，将对象标记成黑色并将它们指向的对象标记成灰色； 使用分布式的终止算法检查剩余的工作，发现标记阶段完成后进入标记终止阶段；   在标记开始的时候，收集器会默认抢占 25% 的 CPU 性能，剩下的75%会分配给程序执行。但是一旦收集器认为来不及进行标记任务了，就会改变这个 25% 的性能分配。这个时候收集器会抢占程序额外的 CPU，这部分被抢占 goroutine 有个名字叫 Mark Assist。而且因为抢占 CPU的目的主要是 GC 来不及标记新增的内存，那么抢占正在分配内存的 goroutine 效果会更加好，所以分配内存速度越快的 goroutine 就会被抢占越多的资源。\n 除此以外 GC 还有一个额外的优化，一旦某次 GC 中用到了 Mark Assist，下次 GC 就会提前开始，目的是尽量减少 Mark Assist 的使用，从而避免影响正常的程序执行。\n标记终止阶段  暂停程序、将状态切换至 _GCmarktermination 并关闭辅助标记的用户程序； 清理处理器上的线程缓存；  清理阶段  将状态切换至_GCoff开始清理阶段，初始化清理状态并关闭写屏障； 恢复用户程序，所有新创建的对象会标记成白色； 后台并发清理所有的内存管理单元，当 goroutine 申请新的内存管理单元时就会触发清理；  清理这个过程是并发进行的。清扫的开销会增加到分配堆内存的过程中，所以这个时间也是无感知的，不会与垃圾回收的延迟相关联。\n总结  Go的GC最早期使用的回收算法是标记-清除算法，该算法需要在执行期间需要暂停应用程序(STW)，无法满足并发程序的实时性。后面Go的GC转为使用三色标记清除算法，并通过混合写屏障技术保证了Go并发执行GC时内存中对象的三色一致性（这里的并发指的是GC和应用程序的goroutine能同时执行）。\n 一次完整的垃圾回收会分为四个阶段，分别是标记准备、标记、结束标记以及清理。在标记准备和标记结束阶段会需要 STW，标记阶段会减少程序的性能，而清理阶段是不会对程序有影响的。\n内存泄漏  尽管有垃圾回收机制，而且 Go 语言的垃圾回收已经做的非常优秀了，很多情况都不需要我们手动的释放内存，但是真的就完全没有问题了么？当然不是，Go 还面临着非常容易出现的内存泄露问题。\n观察如下代码，是否有问题？\n1 2 3 4 5 6 7 8 9 10  var a []int func f(b []int) []int { a = b[:2] return a } func main() { ... }   举个生产环境中的例子，使用 Go 语言开发了一个 Gateway 服务，在发布测试环境后，假设开了3000个 TCP 连接到游戏，游戏数据没有问题，但是发现内存使用量会随着时间的推移持续增加，因此服务的Pod会隔一段时间重启一次。原因是 Gateway 是一个读写分离的 TCP 服务，每一个连接要有两个 goroutine，一个读一个写，但是 TCP 连接断开后，因为时序问题，goroutine会阻塞，一直没有结束，没有释放掉。\n所以，内存泄漏（Memory Leak）是指程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。可以是用 pprof 分析代码性能，配合 graphviz，二者配合能分析程序运行中的系统参数和程序参数等，定位到每个函数，更直观的看出占用内存、使用耗时等情况。\n回到刚才的问题，由于a和b指向同一个底层数组，a是静态存储变量被分配了固定的内存空间，如果程序f(b []int)结束了，b这种动态变量应该被回收了，但是由于a还在使用，尽管只是使用两个元素，后面的元素毫无作用，但是依然不会被GC，所以导致了泄漏。\n1 2 3 4 5 6 7 8 9 10 11  var a []int // 静态存储变量  func f(b []int) []int { // b 是动态存储变量 \ta = b[:2] // a b 都指向同一个底层数组，只不过a只包含[:2]，b是全部 \treturn a } func main() { ... }   模拟一个内存泄漏的例子，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  func main() { go func() { http.ListenAndServe(\u0026#34;0.0.0.0:8090\u0026#34;, nil) }() c := make(chan struct{}) var wg sync.WaitGroup wg.Add(1) for i := 0; i \u0026lt; 10000; i++ { go one(c) } wg.Wait() } func one(c chan struct{}) { var a []int64 for i := 0; i \u0026lt; 10000; i++ { a = append(a, rand.Int63()) } \u0026lt;-c }   这里的 goroutine 用 channel 来模拟阻塞，一直没有关闭，所以内存会爆炸增长。\n提个问题，假设我们正常关闭 goroutine 了，内存就会降下来了么？\n当所有的 goroutine 都结束时，GC 会开始回收切片，但是被回收的内存不会直接换给操作系统，而是由 Go 的 runtime 暂时保管（在 pprof 分析中，参数 HeapIdle 值会变大），接下来如果再次需要分配空间，Go 的 runtime 可以不向操作系统申请内存，直接从自己保管的闲置内存中分配，这样可以提高程序性能。至于 Go 的 runtime 什么时候把这部分内存还给操作系统，不同的分配策略和不同的系统不太一样。\n内存泄漏的常见场景 内存泄漏主要就是 goroutine 泄漏，这里把可能出现的场景都总结一下：\n 获取长字符串中的一段导致长字符串未释放 获取长slice中的一段导致长slice未释放 在长slice新建slice导致泄漏 goroutine泄漏 time.Ticker未关闭导致泄漏 Finalizer导致泄漏 Deferring Function Call 导致泄漏  Goroutine泄漏 Go 语言项目中很常见的内存泄漏是 goroutine 泄漏，导致 goroutine 泄漏有两点原因：\n goroutine 本身的堆栈大小是2 KB，我们开启一个新的 goroutine，至少会占用2KB的内存大小。当长时间的累积，数量较大时，比如开启了 100 万个 goroutine，那么至少就会占用2 GB的内存。 goroutine 中的变量若指向了堆内存区，那么，当该 goroutine未被销毁，系统会认为该部分内存还不能被垃圾回收，那么就可能会占用大量的堆区内存空间。  goroutine 泄漏大概有以下场景：\n 从channel中读或写，但没有对应的写或读  channel 分为两种类型，unbuffered channel和buffered channel，先讨论unbuffered channel。在 channel 被创建后未被关闭前，我们若从 channel 中读取数据，但又一直没有数据写入 channel 中，那么 channel 就会进入等待状态，对应的 goroutine 也就会一直阻塞着了。对应的，当我们往 channel 中写数据，但又一直没有从 channel 中读。那么也会出现被阻塞的情况。至于 buffered channel，其实和 unbuffered channel 情况是类似的，只是 buffered channel 是读完缓存后，或写完缓存后会导致阻塞。\n在使用select时，所有的case都阻塞  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  func add(c, quit chan int) { x, y := 0, 1 for { select { case c \u0026lt;- x: x = x + y case \u0026lt;-quit: fmt.Println(\u0026#34;quit\u0026#34;) return } } } func Add() { c := make(chan int) quit := make(chan int) go add(c, quit) for i := 0; i \u0026lt; 10; i++ { fmt.Println(\u0026lt;-c) } // close(quit) }   当 Add 函数 for 循环了 10 次之后，add 函数就会一直阻塞了，也就出现了 goroutine 泄漏。正确的做法应该是在合适的时间将 quit 关闭，那么 add 协程就可以安全退出了。\ngoroutine 进入死循环  由于代码逻辑的 bug，导致 goroutine 进入了死循环，导致资源无法释放。\n1 2 3 4 5 6 7  func loop() { for { fmt.Println(\u0026#34;loop\u0026#34;) } } go loop()   如何预防 goroutine 泄漏呢？这个问题就要交给开发者自己了，每当我们使用 goroutine 或者 channel 的时候就要想好该如何结束或是如何将其关闭，想好 channel 何时可能出现阻塞，以及阻塞的具体情况，而且避免以死循环的逻辑写代码。\n常见内存面试题  Golang 的内存模型 ( 米哈游 )  将对象分为微小对象、小对象、大对象，使用三级管理结构mcache、mcentral、mheap用于管理、缓存加速span对象的访问和分配，使用精准的位图管理已分配的和未分配的对象及对象的大小。\nGo语言运行时依靠细微的对象切割、极致的多级缓存、精准的位图管理实现了对内存的精细化管理以及快速的内存访问，同时减少了内存的碎片。\n注：如果问的深入，要答四级内存块管理和Mheap的缓存查找、基数树查找等\n简述一下 GC 的原理，三色标记法？( b站 )    初始化状态下所有对象都是白色的。\n  从根节点开始遍历所有对象，把遍历到的对象变成灰色对象\n  遍历灰色对象，将灰色对象引用的对象也变成灰色对象，然后将遍历过的灰色对象变成黑色对象\n  循环上一步骤，知道灰色对象全部变黑色。\n  通过写屏障检测对象有变化。重复以上操作\n  收集所有的白色对象（垃圾）\n  Go的垃圾回收，什么时候触发？( 滴滴 )  主动触发(手动触发)，通过调用 runtime.GC 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。\n被动触发，分为两种方式：\n 使用步调（Pacing）算法，其核心思想是控制内存增长的比例，每次内存分配时检查当前内存分配量是否已达到阈值（环境变量GoGC）：默认100%，即当内存扩大一倍时启用GC。 使用系统监控，当超过两分钟没有产生任何GC时，强制触发 GC。  介绍一下 Go 的 GC ？( 深信服、腾讯、小米、学而思、Aibee、阿里、字节跳动、滴滴、蚂蚁、快手、猿辅导、Shoppe、哔哩哔哩 )  标记清除:\n此算法主要有两个主要的步骤：\n标记(Mark phase)\n清除(Sweep phase)\n第一步，找出不可达的对象，然后做上标记。\n第二步，回收标记好的对象。\n操作非常简单，但是有一点需要额外注意：mark and sweep 算法在执行的时候，需要程序暂停！即 stop the world。\n也就是说，这段时间程序会卡在哪儿。故中文翻译成 卡顿.\n标记-清扫(Mark And Sweep)算法存在什么问题？\n标记-清扫(Mark And Sweep)算法这种算法虽然非常的简单，但是还存在一些问题：\nSTW，stop the world；让程序暂停，程序出现卡顿。\n标记需要扫描整个heap\n清除数据会产生heap碎片\n这里面最重要的问题就是：mark-and-sweep 算法会暂停整个程序。\n三色并发标记法:\n 首先：程序创建的对象都标记为白色。 gc开始：扫描所有可到达的对象，标记为灰色 从灰色对象中找到其引用对象标记为灰色，把灰色对象本身标记为黑色 监视对象中的内存修改，并持续上一步的操作，直到灰色标记的对象不存在 此时，gc回收白色对象 最后，将所有黑色对象变为白色，并重复以上所有过程。  混合写屏障:\n当gc进行中时，新创建一个对象，按照三色标记法的步骤，对象会被标记为白色,这样新生成的对象最后会被清除掉，这样会影响程序逻辑.\ngolang引入写屏障机制.可以监控对象的内存修改，并对对象进行重新标记.\ngc一旦开始，无论是创建对象还是对象的引用改变，都会先变为灰色。\n介绍一下逃逸分析？为什么要逃逸分析？常见的逃逸类型？Go 中的逃逸准则 ( 百度、哔哩哔哩、字节跳动、蚂蚁、网易、阿里 )  为什么需要：通过逃逸分析，那些不需要分配到堆上的变量直接分配到栈上，堆上的变量少了不但同时减少 GC 的压力，还减轻了内存分配的开销。\n常见的类型：func 和 interface 数据类型，channel 或者栈空间不足逃逸。\n准则：如果函数外部没有引用，则优先放到栈中；如果函数外部存在引用，则必定放到堆中;\n如何避免内存逃逸？( 哔哩哔哩、蚂蚁 )   不要盲目使用变量指针作为参数，虽然减少了复制，但变量逃逸的开销更大。 预先设定好slice长度，避免频繁超出容量，重新分配。 一个经验是，指针指向的数据大部分在堆上分配的，请注意。  出现内存逃逸的情况有：\n  发送指针或带有指针的值到channel，因为编译时候无法知道那个goroutine会在channel接受数据，编译器无法知道什么时候释放。\n  在一个切片上存储指针或带指针的值。比如[]*string，导致切片内容逃逸，其引用值一直在堆上。\n  切片的append导致超出容量，切片重新分配地址，切片背后的存储基于运行时的数据进行扩充，就会在堆上分配。\n  调用接口类型时，接口类型的方法调用是动态调度，实际使用的具体实现只能在运行时确定，如一个接口类型为io.Reader的变量r，对r.Read(b)的调用将导致r的值和字节片b的后续转义并因此分配到堆上。\n  在方法内把局部变量指针返回，被外部引用，其生命周期大于栈，导致内存溢出。\n    OK！以上就是对于内存部分的浅显说明，我是将很多大牛的文章内容让自己理解的更好做了总结，如有问题可以联系我进行修改和讨论。 Life is fantastic !\n","date":"2022-06-13T00:00:00Z","image":"https://zonzeeli.github.io/p/memory-management/memorymanagement_hu401943aa3a47c07a1760c3a69afc10a0_2088324_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/memory-management/","title":"Go语言——内存管理"},{"content":"网络连接超时  很多小伙伴可能会在自己网络或者公司办公时想要进行推送和拉取Github仓库，但是由于Github是国外服务器需要挂载VPN才能访问，不过尽管在网页上访问成功了，比如我在Chrome上访问Github，或者是部分公司网络有做限制，需要挂VPN才能访问，测试挂载后可以正常访问bilibili，但是在idea或者是cmd/Terminal上推送依然出现问题，报如下错误：\n1  ...unable to access \u0026#39;xxxxxxx\u0026#39;: Failed to connect to github.com port 443 after 21092 ms: Timed out    该问题是由于代理导致，当挂在VPN时，我们本地的代理服务设置就自动开启了，(这里声明本人以windows11系统为例，系统语言为英语)，如图：\n 如果挂了VPN，这个手动配置代理服务器(Manual proxy setup)应该是会自动开启的，同样，如果没有挂代理这里应该关闭，很多人可能挂了代理关机重启后连不上网，就是因为这里还是开启的，应该关闭，\n 点开编辑(Edit)，可以看到我们的代理ip和port，\n 我们的访问的github也是走这个代理的，所以要在终端运行，\n1 2  git config --global http.proxy 127.0.0.1:10080 // 全局(后面的端口根据自己的端口决定) git config --local http.proxy 127.0.0.1:10080 // 项目(推荐使用)    需要注意一点，这里的端口可能会每次挂在VPN都会变化，所以每次都需要重新配置。\n","date":"2022-04-24T00:00:00Z","image":"https://zonzeeli.github.io/p/gittimeout/gittimeout_hu8668162ba23210b61226a087214b26bb_834236_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/gittimeout/","title":"Git——Github网络连接超时解决方案"},{"content":"内存对齐  在了解内存对齐这个概念之前，我们首先要知道的是32位系统，一次能最大处理的位数，即取出的数据最多为32位，即4个字节，内存对齐的话就是4字节的内存对齐，如果是64位系统，则同理得出是8字节内存对齐。\n 注：以下内容和代码部分选自其他文章。\n 知道了上述前提后，我们要清楚内存中数据存放的形式是怎么样的？如果以大体图来解释的话，如下：\n 所以针对上述对32位和64位系统的解释，我们可以看出，针对32位系统，每4字节的数据放在一起，每次取也是4字节一起取。\n为什么需要内存对齐？  平台问题：并不是所有的硬件平台都能访问任意地址上的任意数据。有些CPU可以访问任意地址上的任意数据，而有些CPU只能在特定地址访问数据，因此不同硬件平台具有差异性，这样的代码就不具有移植性，如果在编译时，将分配的内存进行对齐，这就具有平台可以移植性了。 性能问题：访问未对齐内存需要cpu进行两次访问，对齐后只需要一次。CPU访问内存时并不是逐个字节访问，而是以字长（word size）为单位访问，例如 32位的CPU字长是4字节，64位的是8字节。如果变量的地址没有对齐，可能需要多次访问才能完整读取到变量内容，而对齐后可能就只需要一次内存访问，因此内存对齐可以减少CPU访问内存的次数，加大CPU访问内存的吞吐量。  内存对齐的概念  所以基于以上原因，理论上计算机可以访问任意地址的变量，但是在访问特定类型通常在特定的内存地址中，数据存放并不是随意存放，从上面的图可以得出，是有规则的顺序，我们能够分析出，内存对齐是为了能够快速访问内存进行数据的存取，但是会消耗内存空间，用空间换时间的一种内存存储规则。\nGo语言中内存对齐的体现  首先看一下下面这段代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func main() { s1 := []string{\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;} s2 := []string{\u0026#34;1\u0026#34;} fmt.Println(unsafe.Sizeof(s1)) // 24 \tfmt.Println(unsafe.Sizeof(s2)) // 24  type t1 struct { a int32 b int64 c int32 } type t2 struct { a int32 b int32 c int64 } fmt.Println(unsafe.Sizeof(t1{})) // 24 \tfmt.Println(unsafe.Sizeof(t2{})) // 16 }    是不是对这个结果有疑问呢？为什么s1和s2的数据长度不同，但是打印出的内存长度一样？为什么t1和t2的结构体只是定义的顺序不同，内存长度却不一样？\n 这里要说明一下，go语言通过unsafe.Sizeof(x)打印的变量占用的内存字节数，和底层数据无关，不包含x所指向的内容大小，所以第一个疑问解决了。也同理我们可以通过unsafe.Sizeof()打印出各个类型的内存占用大小。\n 注：这里使用的是64位系统。\n   类型 字节数     bool 1   intN, uintN, floatN, complexN N/8 个字节 （int32 是 4 个字节）   int, uint, uintptr 计算机字长/8 (64位 是 8 个字节)   *T, map, func, chan 计算机字长/8 (64位 是 8 个字节)   string （data、len） 2 * 计算机字长/8 (64位 是 16 个字节)   interface (tab、data 或 _type、data) 2 * 计算机字长/8 (64位 是 16 个字节)   []T (array、len、cap) 3 * 计算机字长/8 (64位 是 24 个字节)     接下来，我们针对结构体的疑惑来讨论，在文章的开头我们已经介绍过，数据在内存中存放的形式。在如下结构体中：\n1 2 3 4 5  type t struct { a bool // 1个字节  b int // 8个字节  c string // 16个字节 }    对于上面的结构，如果是没有进行过内存对齐，则按照存放的顺序，以32位系统的每4个字节取数据的规则，会发现除了a，b和c都不是从头取的，过程如图：\n 这里就有一个问题，对于b和c没有做到从起始位开始取数据，所以会造成之后在再次拼接整理的操作，需要多次内存访问和整理的步骤。而如果经过内存对齐，就会如图：\n 所以我们能发现，内存对齐减少了操作步骤，但是缺浪费了内存空间占用的资源。\n内存对齐的规则  在介绍规则前，go语言unsafe包下还有另外两个函数，unsafe.Alignof()和unsafe.Offsetof()，他们分别是可以获取对齐值和偏移量。这里也介绍一下。\nunsafe.Alignof()  unsafe.Alignof()接受任何类型的表达式，并返回其对齐方式，在结构体中返回的是对应类型字段所需的对齐方式。\n 对于struct结构体，计算每一个unsafe.Alignof(x.f)，unsafe.Alignof(x)是其最大值。 对于array数组，unsafe.Alignof(x)等于构成数组的元素类型的对齐倍数。 对于基础类型，unsafe.Alignof(x)返回为min(字长/8，unsafe.Sizeof(x))，即计算机字长与类型占用内存的较小值。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  func main() { fmt.Println(unsafe.Alignof(int(1))) // 8 -- min(8,8) 64位系统 \tfmt.Println(unsafe.Alignof(true)) // 1 -- min(8,1) \tfmt.Println(unsafe.Alignof(int32(1))) // 4 -- min(8,4) \tfmt.Println(unsafe.Alignof(int64(1))) // 8 -- min(8,8) \tfmt.Println(unsafe.Alignof(complex128(1))) // 8 -- min(8,16)  type t1 struct { a int32 b int64 } t := t1{} fmt.Println(unsafe.Alignof(t.a)) // 4 \tfmt.Println(unsafe.Alignof(t.b)) // 8 \tfmt.Println(unsafe.Alignof(t)) // 8 -- max(4,8) }   unsafe.Offsetof()  知道了每个类型的规则后，就可以使用unsafe.Offsetof()计算结构体内类型的偏移量，官方注释中也说明，which must be of the form structValue.field，所以只有在类型是结构体是才有意义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  func main() { type t1 struct { a int32 // 4个字节 \tb int64 // 8个字节 \tc float32 // 4个字节 \td bool // 1个字节 \t} t := t1{} fmt.Println(unsafe.Offsetof(t.a)) // 0 \tfmt.Println(unsafe.Offsetof(t.b)) // 8 \tfmt.Println(unsafe.Offsetof(t.c)) // 16 \tfmt.Println(unsafe.Offsetof(t.d)) // 20 \tfmt.Println(unsafe.Alignof(t)) // 8 \tfmt.Println(unsafe.Sizeof(t)) // 24 }    可能对于这个偏移量的计算结果有些疑惑，这个unsafe.Offsetof()其实就是在内存对齐之后计算出来的偏移量，即计算特定的地址了，所以这一步需要先看规则。\n内存对齐规则  成员对齐规则：针对一个基础类型变量，如果unsafe.AlignOf()返回的值是m，那么该变量的地址需要被m整除（如果当前地址不能整除，填充空白字节，直至可以整除）。 整体对齐规则：针对一个结构体，如果unsafe.AlignOf()返回值是m，需要保证该结构体整体内存占用是m的整数倍，如果当前不是整数倍，需要在后面填充空白字节。   针对该规则，我们再把上述的结构体和unsafe.Offsetof()拿出来分析一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  func main() { type t1 struct { a int32 // 4个字节 \tb int64 // 8个字节 \tc float32 // 4个字节 \td bool // 1个字节 \t} t := t1{} fmt.Println(unsafe.Offsetof(t.a)) // 0 \tfmt.Println(unsafe.Offsetof(t.b)) // 8 \tfmt.Println(unsafe.Offsetof(t.c)) // 16 \tfmt.Println(unsafe.Offsetof(t.d)) // 20 \tfmt.Println(unsafe.Alignof(t)) // 8 \tfmt.Println(unsafe.Sizeof(t)) // 24 \t// 假设从地址0开始 \t// unsafe.Sizeof(int32(1)) = 4，unsafe.Alignof(int32(1)) = 4，地址0开始，可以被4整除 \t// unsafe.Sizeof(int64(1)) = 8，unsafe.Alignof(int64(1)) = 8，地址需要从8开始，才可以被8整除，[4,8]的位置用0来补充 \t// unsafe.Sizeof(float32(1)) = 4，unsafe.Alignof(float32(1)) = 4，地址需要从16开始，可以被4整除，[8,16]的位置被t.b占满 \t// unsafe.Sizeof(true) = 1, unsafe.Alignof(true) = 1, 地址从20开始即可，[16,20]的位置被c沾满。 \t// 由于结构体也需要对齐，要被8整除，所以要补0到24。 }    有一点需要注意，就是如果结构体内部嵌入了空结构体，那么当空结构体位于结构体的前面和中间位置，并不会占用内存，如果是末尾的话，需要内存对齐，占用的空间和前一个变量保持一致。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  type C struct { a struct{} b int64 c int64 } type D struct { a int64 b struct{} c int64 } type E struct { a int64 b int64 c struct{} } type F struct { a int32 b int32 c struct{} } func main() { fmt.Println(unsafe.Sizeof(C{})) // 16 \tfmt.Println(unsafe.Sizeof(D{})) // 16 \tfmt.Println(unsafe.Sizeof(E{})) // 24 \tfmt.Println(unsafe.Sizeof(F{})) // 12 }     OK！以上就是内存对齐的介绍了，从上面的介绍可以看出，在开发过程中，我们可以调整结构体内变量的位置来优化内存占用。\n Life is fantastic !\n","date":"2022-03-29T00:00:00Z","image":"https://zonzeeli.github.io/p/memory-alignment/memoryalignment_hu02570da8dff591db14e92b986bdd1dc3_682341_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/memory-alignment/","title":"Go语言——内存对齐"},{"content":"Map  Map是go语言的一种数据结构，它是一种无序的键值对集合。go语言的map是使用hashmap实现的。使用数组+链表的形式，用拉链法消除hash冲突。go语言中的map主要是由两种结构组成，hmap和bmap。 以下结构内容和代码选自其他文章。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  type hmap struct { count int //元素个数，调用len(map)时直接返回  flags uint8 //标志map当前状态,正在删除元素、添加元素.....  B uint8 //单元(buckets)的对数 B=5表示能容纳32个元素  noverflow uint16 //单元(buckets)溢出数量，如果一个单元能存8个key，此时存储了9个，溢出了，就需要再增加一个单元  hash0 uint32 //哈希种子  buckets unsafe.Pointer //指向单元(buckets)数组,大小为2^B，可以为nil  oldbuckets unsafe.Pointer //扩容的时候，buckets长度会是oldbuckets的两倍  nevacute uintptr //指示扩容进度，小于此buckets迁移完成  extra *mapextra //与gc相关 可选字段 } //a bucket for a Go map type bmap struct { tophash [bucketCnt]uint8 } //实际上编辑期间会动态生成一个新的结构体 type bmap struct { topbits [8]uint8 // 高位哈希值  keys [8]keytype values [8]valuetype pad uintptr overflow uintptr // 指向扩容后的bucket }    由上面的结构可知，key和value都存在bmap中，且不是以指针形式，最多存放8个，key存放位置由高位哈希值决定，低位哈希值用于选择把kv存放在bmap数组中的哪一个里。具体为在存储key时不能重复，如果key重复，value会进行覆盖，通过key进行哈希运算，然后进行计算得到位置，但是这样会出现哈希冲突的问题，go语言的解决方法是用拉链法解决哈希冲突，也就是用链表，在冲突位置的元素上形成一个链表，通过指针互连接，在查找的时候如果发现key冲突了，会顺着链表一直向下找，直到尾节点，找不到则返回空。\n overflow指针指向的是扩容后的下一个bmap，会把overflow指针存到extra中。\n1 2 3 4 5 6 7 8  type mapextra struct { // overflow[0] contains overflow buckets for hmap.buckets.  // overflow[1] contains overflow buckets for hmap.oldbuckets.  overflow [2]*[]*bmap // nextOverflow 包含空闲的 overflow bucket，这是预分配的 bucket  nextOverflow *bmap }    overflow是一个指针，看结构的定义，在map哈希冲突过多时，会发生扩容，为了不全量搬迁数据，使用增量搬迁，所以按照解释说的，[0]时当前溢出桶的集合，[1]是发生扩容后，保留旧的溢出桶集合，overflow存在的意义在于防止溢出桶被gc。 而bmap的内存模型如下，\n1  |...|key0|key1|key2|key3|value0|value1|value2|value3|*overflow|    可以观察到，key和value并不是键值对的形式存储，是独立分开按照顺寻存放，目的是为了减少pad字段，消除padding(内存对齐)带来的空间浪费。比如：map[int64]int8,如果以key-value的形式存储就必须在每个value后面添加padding7个字节，如果以上述的形式只需要在最后一个value后面添加padding就可以了。 下面是整个map的大体构造： 接下来简单说一下map的创建函数\n1 2 3 4 5 6 7 8  func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } ...... return h }    我们观察到，其实每次make(map[key]value)返回的是指针，而每次复制，比如a := b这种操作，也是创建指针副本，复制了hmap的指针，都是共享一个map，使用起来很像引用，这个和slice的底层数组不同，每次map的扩容，所有都是共享一个map。 下面是go语言中map存储赋值的部分源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { //获取hash算法  alg := t.key.alg //计算hash值  hash := alg.hash(key, uintptr(h.hash0)) //如果bucket数组一开始为空，则初始化  if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1)  } again: // 定位存储在哪一个bucket中  bucket := hash \u0026amp; bucketMask(h.B) //得到bucket的结构体  b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) +bucket*uintptr(t.bucketsize))) //获取高八位hash值  top := tophash(hash) var inserti *uint8 var insertk unsafe.Pointer var val unsafe.Pointer bucketloop: //死循环  for { //循环bucket中的tophash数组  for i := uintptr(0); i \u0026lt; bucketCnt; i++ { //如果hash不相等  if b.tophash[i] != top { //判断是否为空，为空则插入  if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) val = add( unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize) ) } //插入成功，终止最外层循环  if b.tophash[i] == emptyRest { break bucketloop } continue } //到这里说明高八位hash一样，获取已存在的key  k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } //判断两个key是否相等，不相等就循环下一个  if !alg.equal(key, k) { continue } // 如果相等则更新  if t.needkeyupdate() { typedmemmove(t.key, k, key) } //获取已存在的value  val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) goto done } //如果上一个bucket没能插入，则通过overflow获取链表上的下一个bucket  ovf := b.overflow(t) if ovf == nil { break } b = ovf } if inserti == nil { // all current buckets are full, allocate a new one.  newb := h.newoverflow(t, b) inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) val = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/value at insert position  if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectvalue() { vmem := newobject(t.elem) *(*unsafe.Pointer)(val) = vmem } typedmemmove(t.key, insertk, key) //将高八位hash值存储  *inserti = top h.count++ return val }    有一个地方要注意一下go语言的map，通过key获取到value，value是不可寻址的，因为map会进行动态扩容，进行扩展后，map的value会进行内存迁移，其地址会发生变化，无法对这个value进行寻址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  func main() { type test struct { t string } testmap := make(map[string]test) testmap[\u0026#34;test\u0026#34;] = test{t: \u0026#34;ZonzeeLi\u0026#34;} // 这一行编译不通过 \ttestmap[\u0026#34;test\u0026#34;].t = \u0026#34;Changed\u0026#34; // 这个不是复制map，不会对原map有影响 \tp := testmap[\u0026#34;test\u0026#34;] p.t = \u0026#34;Changed again\u0026#34; }   Map的扩缩容机制  map最重要且最多问的就是其扩容机制，这里把扩缩容都简单总结一下。 有两种情况要扩容，一种是kv太多，超过负载，另一种是overflow的bucket过多。第一种情况当扩容时，go语言会将bucket数组的数量扩充一倍，产生一个新的bucket数组，并且将就数组的数据迁移至新数组中，如果是bucket过多，也就是第二种情况，扩容后的bucket数量不变，做内存整理。我们来解释一下扩充的过程，当map的长度增大到大于负载因子所需的长度，会去申请一个新的大数组作为bucket，即 newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)，回将旧的bucket数组存放在oldbucket中做填充，这里并不是立即把旧的数组中的数据转移到新的newbucket中，而是只有在访问到具体的某个bucket时，才会把数据转移到新的newbucket中，如下图： 注：这里并不会直接删除旧的bucket，而是把原来的引用去掉，利用gc清除内存。 那么在这里就可以联想到，map的删除操作，如果key是一个指针类型，则将其置空，等待gc清除，如果是值，则清楚相关内存，对value也是相关操作，最后会把key对应的高位值对应的数组index置为空。但是map的delete操作，会有可能出现很多空的kv，会导致搬迁操作。\n1 2 3 4 5 6 7 8  func hashGrow(t *maptype, h *hmap) { bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } ... }    无论是扩容还是缩容，对应的代码段都是这一段，如果是扩容，则bigger = 1，否则容量不变，所以缩容，对于内存空间的占用来说并没有发生改变。所以针对上述介绍的map的delete操作，不注意管理会使分配的内存不断增加。\nMap的并发安全问题  go语言的map并不支持并发读写，也就是非线程安全的，这一点和slice真的是难兄难弟。如果有多个goroutine操作，代码写法不当会报错fatal error: concurrent map writes，无论是在读在写的过程中，甚至是写一个http的请求服务，每次都要读一个map，在高并发的场景下也会报这样的错，而在其他时候并不会，所以这是一个隐式问题。那么该如何处理呢？\n1 2 3 4  var b = struct{ sync.RWMutex m map[string]int }{m: make(map[string]int)}    最常见的就是加一个锁，定义一个结构体包含一个map结构体和一个嵌入读写锁sync.RWMutex。读写数据分别如下：\n1 2 3 4 5 6 7 8 9  // 读数据 b.RLock() a := b.m[\u0026#34;test\u0026#34;] b.RUnlock() // 写数据 b.Lock() b.m[\u0026#34;test\u0026#34;] ++ b.Unlock()    而go语言自身提供了一种type Map，即sync.Map，是一种支持并发读写的map，其中包含两个数据结构read和dirty，减少锁对性能的影响。\n1 2 3 4 5 6  type Map struct { mu Mutex read atomic.Value // readOnly \tdirty map[interface{}]*entry misses int }   1 2 3 4 5 6  func (m *Map) Delete(key interface{}) func (m *Map) Load(key interface{}) (value interface{}, ok bool) func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) func (m *Map) Range(f func(key, value interface{}) bool) func (m *Map) Store(key, value interface{})    对于sync.Map结构，更适合读多写少的场景，我之前看到了煎鱼大佬对sync.Map内部结构的分析和为什么适合读多写少的性能测试，感兴趣的可以看一下这篇文章。\n  OK!有关go语言map的介绍就这么多了，至于扩容内部源码的分析、搬迁操作等可以再细致的对应代码去理解。\n Coding every day！\n","date":"2022-03-25T00:00:00Z","image":"https://zonzeeli.github.io/p/map/gomap_hueb06b1d9a0d79dfdcc90f95f1ba3b9ea_886458_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/map/","title":"Go语言——Map的底层介绍及扩缩容机制"},{"content":"延迟函数(defer)  延迟函数，顾名思义，是在之后执行的函数，那么具体怎么个之后法呢？在函数调用的过程中，可以理解为调用函数的过程是一个链表，a-\u0026gt;b-\u0026gt;c，整个调用过程是先a再b再c，而延迟函数就是在调用a的程序过程中写入一个延迟执行，在a函数return之后添加一个函数调用。因此，defer的常用功能为释放资源、关闭连接、捕获错误等，这是一种语言保护机制。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13  func Open() { f, err := os.Open(\u0026#34;\u0026#34;) if err != nil { return } // 如果此处Open函数没有问题，继续向下 \ts, err := os.Create(\u0026#34;\u0026#34;) if err != nil { return // 如果此处发生error，那么直接return，后面的两个close都不执行 \t} f.Close() s.Close() return }    上面这段代码中如果Open函数正常执行，但是Create函数错了，返回错误时下面的close函数没有办法执行，就会导致f没有关闭，但是我们又不能直接写在上面，因为还没对f进行操作就关闭了文件，所以这里就要使用延迟函数了。\n1 2 3 4 5 6 7  func Open() { f, err := os.Open(\u0026#34;\u0026#34;) if err != nil { return } defer f.Close() // 注意这里还有一个坑，下面再介绍 }    接下来我们就介绍defer的使用：\ndefer的执行参数  defer的执行参数在defer写入的位置就已经确定好了，也就是说，defer并不只是单单在return之后执行，而是在准备延迟调用的时候，就已经把参数一并压入堆栈中等待执行。\n1 2 3 4 5 6 7  func main() { x := 5 defer fmt.Println(x) // 这个时候已经将x=5传参给print函数了 \tx++ fmt.Println(x) // 结果打印为6 5 (注意正常是换行打印，为了看起来方便就这么写了，后面也一样) }    思考一下这样写结果呢？\n1 2 3 4 5 6 7 8 9  func main() { x := 5 defer func() { fmt.Println(x) // 这里相当于一个闭包，defer执行的是一个func()，但是func()不需要任何参数，而是去执行打印x，这时候x就打印出为6了，请区分和下面的匿名函数的问题 \t}() x++ fmt.Println(x) // 结果打印为6 6 }   defer的执行顺序  在知道了defer的执行参数后就需要知道defer的执行顺序，如果有多条defer语句的话，根据压入顺序，最后是逆序执行的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  func main() { x := 5 defer func() { // 最后执行 \tfmt.Println(x) }() defer func() { // 再执行 \tfmt.Println(\u0026#34;ZonzeeLi\u0026#34;) x++ }() defer func() { // 先执行 \tfmt.Println(\u0026#34;你好\u0026#34;) }() // 结果打印为 你好 ZonzeeLi 6 }   defer对匿名返回值的返回处理  我们在自己写一个func()的时候经常会写返回值，但是返回值时分命名和匿名两种，这在defer中又有区别了，我们看下面代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  func f1() int { x := 5 defer func() { x++ // 在这个地方加一个打印x，看看结果是多少？ \t}() return x // 这个函数返回5 } func f2() (x int) { // 如果把这个x换成y的话，返回结果是多少？ \t//x = 0 \tdefer func() { x++ }() return 5 // 这个函数返回6 } func f4() (x int) { // 这个返回是多少？ \tdefer func(x int) { x++ // 这里加一个打印x，打印的是多少？ \t}(x) return 50 // 这个结果返回为50，请自行思考，解释参考上面的defer执行参数 }    f1中使用的是匿名返回值，f2中使用的是命名返回值，f1的匿名返回值，相当于返回x的一个副本给f1的return，所以对x进行x++操作没有对return进行影响，而有命名返回值则不同，defer的作用域始终是在这个函数内的，所以使用的返回值就是x。\ndefer panic recover的配合使用 1 2 3 4 5 6 7 8  func test() { panic(1) } func main() { test() // 结果为panic: 1， 不会打印2 \tfmt.Println(2) }    我们知道如果函数panic了，就直接终止运行了，后面的语句都不会执行，但是如果我们想要执行的话就需要recover，这时候defer的延迟使用就非常有帮助了。\n1 2 3 4 5 6 7 8 9 10 11 12 13  func test() { defer func() { if err := recover(); err != nil { fmt.Println(\u0026#34;捕获成功啦！\u0026#34;) } }() panic(1) } func main() { test() fmt.Println(2) // 结果为 捕获成功啦！2 }    另外这里要注意的是，如果连续调用panic，仅最后一个会被recover捕获。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  func main() { defer func() { for { if err := recover(); err != nil { log.Println(err) } else { log.Fatalln(\u0026#34;fatal\u0026#34;) } } }() defer func() { panic(\u0026#34;you are dead\u0026#34;) }() panic(\u0026#34;i am dead\u0026#34;) // 结果为 \t// 2022/03/08 15:58:08 you are dead \t// 2022/03/08 15:58:08 fatal }    既然说到这，我就补充一下，defer中直接调用recover是无效的，举例如下：\n1 2 3 4 5 6  func main() { defer log.Println(recover()) // 无效 \tdefer recover() // 无效 \tpanic(\u0026#34;i am dead\u0026#34;) }   常见的defer面试题和坑  以上将defer的几个用法介绍完了，下面我总结了在一些博主的文章中看到的问题和平常遇见的坑：\n问题一，一道面试题，出自李文周的博客 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func calc(index string, a, b int) int { ret := a + b fmt.Println(index, a, b, ret) return ret } func main() { x := 1 y := 2 defer calc(\u0026#34;AA\u0026#34;, x, calc(\u0026#34;A\u0026#34;, x, y)) // 先执行了calc(\u0026#34;A\u0026#34;, x, y)，然后再压入defer执行语句和defer需要的参数 \tx = 10 defer calc(\u0026#34;BB\u0026#34;, x, calc(\u0026#34;B\u0026#34;, x, y)) y = 20 // 结果打印为 \t// A 1 2 3 \t// B 10 2 12 \t// BB 10 12 22 \t// AA 1 3 4 }    上面的这个解释还是主要由defer的执行参数有关系，首先再执行defer calc(\u0026quot;AA\u0026quot;, x, calc(\u0026quot;A\u0026quot;, x, y))，他的三个参数就已经确定了，那么第三个参数是由calc(\u0026quot;A\u0026quot;, x, y)的返回值决定的，所以这个时候就会先执行这一条，然后将参数一同压入栈，将延迟函数压入函数调用，下面的defer calc(\u0026quot;BB\u0026quot;, x, calc(\u0026quot;B\u0026quot;, x, y))也同理。\n问题二，for循环导致性能问题，出自《Go语言学习笔记》 1 2 3 4 5 6 7  func test() { ... for i := 0;i \u0026lt; n;i ++ { f, _ := os.Open(\u0026#34;\u0026#34;) defer f.Close() } }    上面的代码其实没什么运行问题，只是defer的执行需要尽心很多压栈出栈以及内存使用的操作，会消耗很多资源，所以应该直接执行或者封装。\n问题三，defer语句的位置，出自牛客网Go语言面试题 1 2 3 4 5 6 7 8 9 10  func Open() { f, err := os.Open(\u0026#34;\u0026#34;) defer f.Close() if err != nil { ... return } // defer f.Close() \t... }    上面的代码写法有什么问题？也正常执行延迟Close了？问题在于defer语句的位置，如果写在判断err然后return之前，如果Open发生异常，那么f就是空指针，在return之后执行defer f.Close()就会报空指针错误，所以要在处理玩错误，return之后执行defer。\n问题四，如下代码，当函数deferDemo()返回失败时，并不能destroy已create成功的资源，这一说法是否正确，出自牛客网Go语言面试题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  func deferDemo() error { err := createResource1() if err != nil { return ERR_CREATE_RESOURCE1_FAILED // 如果1失败，直接返回没有任何创建成功的资源 \t} defer func() { if err != nil { destroyResource1() } }() err = createResource2() if err != nil { return ERR_CREATE_RESOURCE2_FAILED // 如果2创建失败，那么执行上面的defer，destroy已经创建的1 \t} defer func() { if err != nil { destroyResource2() } }() err = createResource3() if err != nil { return ERR_CREATE_RESOURCE3_FAILED // 同理 \t} defer func() { if err != nil { destroyResource3() } }() return nil }    正确答案是错误，也就是如果返回失败，可以destroy已经create的资源，解释如下，如果返回成功，不需要讨论，如果返回失败，我们假设在createResource1()处失败，这时候2、3都没有进行创建，1也没有创建成功，直接返回，所以没有创建成功的资源，不需要destroy，如果在createResource2()，这时候err有了值，在返回2失败后，执行了上面1成功后压入的defer，破坏了1，下面的3也同理。\n问题五，下面这段话是否正确，出自牛客网Go语言面试题  当程序运行时，如果遇到引用空指针、下标越界或显式调用panic函数等情况，则先触发panic函数的执行，然后调用延迟函数。调用者继续传递panic，因此该过程一直在调用栈中重复发生：函数停止执行，调用延迟执行函数。如果一路在延迟函数中没有recover函数的调用，则会到达该协程的起点，该协程结束，然后终止其他所有协程，其他协程的终止过程也是重复发生：函数停止执行，调用延迟执行函数。这一说法是否正确。\n 答案是错误的，上面的这段话需要注意的是一个地方，则先触发panic函数的执行，然后调用延迟函数，panic是需要等defer结束后才会向上传递，出现panic，会先按照defer的逆序执行顺序，执行完之后才会执行panic。有一段大佬的完整解释为：“当内置的panic()函数调用时，外围函数或方法的执行会立即终止。然后，任何延迟执行(defer)的函数或方法都会被调用，就像其外围函数正常返回一样。最后，调用返回到该外围函数的调用者，就像该外围调用函数或方法调用了panic()一样，因此该过程一直在调用栈中重复发生：函数停止执行，调用延迟执行函数等。当到达main()函数时不再有可以返回的调用者，因此这个过程会终止，并将包含传入原始panic()函数中的值的调用栈信息输出到os.Stderr”，可以举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  func test() { defer fmt.Println(\u0026#34;test.1\u0026#34;) defer fmt.Println(\u0026#34;test.2\u0026#34;) panic(\u0026#34;i am dead\u0026#34;) } func main() { defer func() { log.Println(recover()) }() test() // 结果为 \t// test.2 \t// test.1 \t// 2022/03/07 15:53:27 i am dead }   问题六，思考结果，出自coding进阶公众号文章 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  func bar() (r int) { defer func() { r += 4 // 3. r += 4 \tif recover() != nil { // 4. recover()捕获成功 \tr += 8 // 5.r += 8 输出 13 \t} }() var f func() defer f() // 2.先执行这个，但是因为defer语句的位置，f()报错 \tf = func() { r += 2 } return 1 // 1.先给r进行赋值 } func main() { println(bar()) //结果为13 }    答案是13，你思考对了么？这道题的关键在于那个defer f()，此处因为defer语句的写法位置，因为var f func()，f()是空指针，而直接进行defer f()，在对f()赋值，所以在defer中会panic，这个就和上面说的问题三一样了，所以正确的执行顺序是，返回1给r，然后defer f()直接panic，再向上进行，r += 4然后再recover()捕获了panic，执行了r += 8。\n问题七，思考结果，出自coding进阶 1 2 3 4 5 6 7 8 9 10 11 12  func main() { defer func() { fmt.Print(recover()) // 4.同理捕获到了1 \t}() defer func() { defer fmt.Print(recover()) // 2.先解析了参数，所以这里先执行了recover()，这时候还没有按照defer的逆序执行，所以先把2捕获到了 \tdefer panic(1) recover() // 3.有效，但是被截胡了 \t}() defer recover() // 1.无效 \tpanic(2) }    结果是21，你回答对了么？我猜测多数人会回答nil1，还有人会回答nil，我这里分别解释一下，回答nil的是因为没理解recover的使用，recover必须配合defer的函数体直接调用使用，否则都会捕获无效，这个在上面都有介绍到，所以第一个defer(从下往上)是无效的，回答为nil1的是注意到了很多，但是最关键的在fmt.Print(recover())中，recover()作为参数被defer中的func调用，要先执行参数解析，所以2就会被先捕获到，而不是正常的先捕获经过头插法的最近panic，同理最上面的defer就捕获到了1。\n  延迟函数defer的基础使用就差不多介绍这些，具体太细的，以及配合panic和recover使用的需要看底层和汇编才能理解的更透彻。\n Coding every day，let\u0026rsquo;s go!\n","date":"2022-03-08T00:00:00Z","image":"https://zonzeeli.github.io/p/defer/godefer_hu7e4671ba8c4acd05ae2c2aa9b1ac6fe3_177012_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/defer/","title":"Go语言——延迟函数defer的使用"},{"content":"切片(Slice)  初学go语言的小伙伴可能在切片和数组(Array)上有很多困惑，而经常出问题使用错误的就是切片slice，首先要知道的是切片的底层结构：\n1 2 3 4 5  type slice struct { array unsafe.Point // 指向底层数组的指针 \tlen int // 切片的长度 \tcap int // 切片的容量 }    观察上面的结构，我们可以理解为slice是只是指向一个数组，并不是真的申请了一篇内存来保存数组，比如如果一个底层数组有10个元素，slice可以访问其中的前5个数，这样子slice的地址和数组的头地址就是一样的，而且slice可以共享底层数组。\n 而且这里要说明一下，Go语言类型都是值类型，只不过有的类型内部使用是用指针实现，所以可以实现引用，而数组的声明要带有长度，如果声明好了，则长度是不会发生改变的，如果想要扩容那么只能新声明一个新数组，这个和slice完全不同。\n1 2 3 4 5  var a [5]int a = append(a, 6) b := [5]int{1,2,3,4,5} b = append(b, 6) // 会有如下错误提示:Cannot use \u0026#39;a\u0026#39; (type [5]int) as the type []Type    这里有一点因为上面说到的值类型，如果在函数调用中传参为数组的话，那么没调用一次就会将数组的内存空间大小分配在栈中，如果数组过大那么就会很影响内存的利用，所以slice，利用指向数组的指针，传参用slice就会解决这个问题。\n1 2 3 4 5 6 7  func test1(arr [5]int) { ... } func test2(arr []int) { ... }    slice的声明可以定义好长度和容量，也可以不设定定义为nil或是空切片。\n1 2 3 4  var a []int // 长度和容量均为0，nil切片 \tb := []int{1, 2} // 长度和容量均为2 \tc := make([]int, 0) // 空切片 \td := make([]int,1, 2)    由于slice是指向底层数组的指针，且可以共享底层数组，所以两个指向同一个底层数组的切片，对其中一个修改值，会影响另一个\n1 2 3 4 5 6 7 8  a := []int{1, 2, 3, 4, 5, 6} b := a[2:4] fmt.Println(len(a), cap(a), len(b), cap(b)) // 这里打印的结果是6 6 2 4 \t// b的长度计算方式是4-2，容量的计算方式是a的容量6减b其实索引2 \tfmt.Println(b) // [3 4] \tb[0] = 10 fmt.Println(b, a) // [10 4] [1 2 10 4 5 6] 这面由于指向同一个底层数组，所以打印a也会变化 \tfmt.Println(b[:3]) // [10 4 5] 因为b的容量是4，b指向从索引2开始，所以打印出来的是[10 4 5]，但是不能打印b[3]，因为b的长度是2，只能访问长度范围内的索引    slice相对于数组来说可以直接使用append来扩容增长，如果slice的容量够，append方法不会改变底层数组，不够的话，append 会创建一个新的底层数组，拷贝原先的值和添加新值。但是因为slice是指向数组指针的原因，这其中又有一些问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  a := []int{1, 2, 3, 4, 5, 6} b := a[2:4] fmt.Println(len(a), cap(a), len(b), cap(b)) // 6 6 2 4 \tb = append(b, 10) fmt.Println(b, a) // [3 4 10] [1 2 3 4 10 6] \tfmt.Println(len(a), cap(a), len(b), cap(b)) // 6 6 3 4 b的长度增长了，容量因为没有超出所以没有变化，底层数组也没有变，a[4]发生了变化。 \tb = append(b, 20) fmt.Println(len(a), cap(a), len(b), cap(b)) // 6 6 4 4 \tb = append(b, 30) fmt.Println(len(a), cap(a), len(b), cap(b)) // 6 6 5 8 超出原先b的容量，b扩容了，此时b的底层数组不是a的底层数组了，扩容机制这个我记得是小于1024个元素容量扩容每次乘2，大于1024时是乘1.25，我并不太确定。 \tfmt.Println(b, a) // [3 4 10 20 30] [1 2 3 4 10 20] \tb[0] = 100 fmt.Println(b, a) // [100 4 10 20 30] [1 2 3 4 10 20] a 没有发生变化 \tc := []int{1, 2, 3, 4, 5} d := c[2:4:5] // 这种写法就是三种参数的写法，d的长度是2，容量是5-3，这里的第三个参数不能超过c的容量，不然会报错 \tfmt.Println(d, len(d), cap(d)) // [3 4] 2 3 \t// 这样做限定了容量最大值，如果d扩容超过最大容量，就会创建新的底层数组，不会影响c了    大体的切片知识就是这样，实际中可能还会有很多问题，前一阵子看到煎鱼大佬得一篇文章，这里把这篇文章的主要内容拿出来聊聊。首先放上煎鱼大佬的文章链接，接下来看一下这段程序，思考一下这段代码的输出是怎么样的？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  sl := make([]int, 0, 10) var appenFunc = func(s []int) { s = append(s, 10, 20, 30) fmt.Println(s) } fmt.Println(sl) appenFunc(sl) fmt.Println(sl) fmt.Println(sl[:10]) //[] \t//[10 20 30] \t//[] \t//[10 20 30 0 0 0 0 0 0 0]    看到输出的话问题来了，最让人疑惑的就是后两句打印。\n1 2  fmt.Println(sl) fmt.Println(sl[:10])    另外再加一句fmt.Println(sl[:])猜一下打印结果如何？整合一下结果应该如下：\n1 2 3 4 5 6 7  fmt.Println(sl) fmt.Println(sl[:10]) fmt.Println(sl[:]) //[] \t//[10 20 30 0 0 0 0 0 0 0] \t//[]    更加令人疑惑了？为什么后两句的打印结果不一样呢？再看完了以上切片的介绍，以及知道Go语言是值类型传递的，我们来分析这段程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  sl := make([]int, 0, 10) var appenFunc = func(s []int) { fmt.Println(len(s), cap(s)) // 0 10 没什么争议 \ts = append(s, 10, 20, 30) fmt.Println(len(s), cap(s)) // 3 10 没什么争议 \tfmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;s) // 0xc000004108 没什么争议，再解释一下Go语言是值类型传递，所以闭包种的s相当于一个副本，所以地址和sl的地址不一样，但是重点！！！s指向的底层数组和sl指向的是一样的，这是解决这些问题的关键所在。 \t} fmt.Println(sl) // [] 为空，没什么争议 \tfmt.Printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;sl) // 0xc0000040d8 \tappenFunc(sl) // 看上面咯 \tfmt.Println(sl) // [] 为空，因为是值传递所以sl的长度不变，容量也不变，但是再仔细思考一下底层数组变了么？答案是变了 \tfmt.Println(sl[:10]) // [10 20 30 0 0 0 0 0 0 0] 没错 底层数组变了，而且sl的容量是10可以打印，所以将底层数组打印出来了 \tfmt.Println(sl[:]) // [] 为空，前面说了sl的长度不会改变，所以其实sl的长度依然是0！！！那这么打印就不会有任何结果的 \tfmt.Println(len(sl), cap(sl)) // 0 10 到这应该就完全理解了 \t// 这里也说明一下，比如fmt.Println(sl)为什么打印的不是完整底层数组这种的问题，这其实和fmt包下打印方法的写法有关，这里就不深研究这个了。    看了上面一步步的分析后，是不是理解了很多，其实环环相扣，清晰了理解起来就很容易，过了一阵子后，煎鱼大佬又又发了篇关于slice的文章，这里也拿出来说一下，是有关slice操作导致内存泄露的问题，还是依然看一下如下程序，判断一下是否会导致内存泄漏：\n1 2 3 4 5 6 7 8 9 10  var a []int func f(b []int) []int { a = b[:2] return a } func main() { ... }    这里先简单说一下内存泄漏，内存泄露是在程序运行过程中不再使用的内存，没有被释放掉，导致这些内存无法被使用，等到程序结束后才会释放掉，Go语言也有GC垃圾回收机制回收堆上不使用的内存，但代码写法的问题依然会造成内存泄漏。而Go语言的内存泄漏主要是goroutine泄漏，这个之后写博客可以介绍介绍，回到这个问题，上面的这个代码无疑是会造成内存泄漏的，那么问题在哪？答案还是在slice的底层结构上，分析下这段程序：\n1 2 3 4 5 6 7 8 9 10 11  var a []int // 静态存储变量  func f(b []int) []int { // b 是动态存储变量 \ta = b[:2] // 跟着上文的介绍，a b 都指向同一个底层数组，只不过a只包含[:2]，b是全部 \treturn a } func main() { ... }    到这其实就很明了了，由于a和b指向同一个底层数组，a是静态存储变量被分配了固定的内存空间，如果程序f(b []int)结束了，b这种动态变量应该被回收了，但是由于a还在使用，尽管只是使用两个元素，后面的元素毫无作用，但是依然不会被GC，所以导致了泄漏，煎鱼大佬还给了一个解决方案，也同样是利用了slice的append特性，程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12  var a []int var c []int // 第三者  func f(b []int) []int { a = b[:2] // 新的切片 append 导致切片扩容 \tc = append(c, b[:2]...) fmt.Printf(\u0026#34;a: %p\\nc: %p\\nb: %p\\n\u0026#34;, \u0026amp;a[0], \u0026amp;c[0], \u0026amp;b[0]) return a }    这里的a和b是指向同一个底层数组，而c是通过没有容量的切片，进行append后重新申请分配空间的变量，因此使用c实现了防止内存泄漏。\n OK！有关slice的部分暂时能想到的就这些，也先介绍这么多啦~\n","date":"2022-02-23T00:00:00Z","image":"https://zonzeeli.github.io/p/slice/goslice_hu1b4159d9ef01abf89b1c5b948d41a0fb_1054267_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/slice/","title":"Go语言——切片(Slice)的坑"},{"content":"程序员之歌 99 little bugs in the code,\n99 bugs in the code,\nfix one bug, compile it again,\n101 little bugs in the code.\n101 little bugs in the code….\n(Repeat until BUGS = 0)\n1024  首先特意的在10月24日发布这篇博客，主要目的当然是祝各位程序员节日快乐，当然这个时期也是找工作的、考研考公的、准备毕业的等等最忙碌最紧张的时期，也祝大家一切顺利。我在前几天偶然间看到了宋宝华的一篇文章，《Linux中的1024——给阅码场Linuxer们的节日祝福》。感觉1024这个数字对于程序员来说真的很神奇，也非常重要。在文中，他介绍到：\n 1024是程序员的狂欢节。基于二进制的原理，程序员通常会把1024当做一个整数而不是1000。程序员这个行业处理“bit”，当然这个行业“苦逼”，这也让我轻松地记住了一个单词——bitter。bitter的意思就是“苦的”，bit后面加er后缀，是人，这里只是会意记单词。er通常表明比较loser的人，英语里面一般地位崇高的人，后缀是-or。比如：carpenter 木匠 vs. doctor 博士，programmer 程序员 vs. professor 教授，coder码农 vs. director 总监。为啥咱们不叫programmor，不叫codor，原因应该是很清楚了。人艰不拆，当然我们也不要妄自菲薄，这里仅仅是开一个玩笑，让大家在自己的节日里比较欢乐。\n而他也介绍到，作为熟悉Linux的程序员，我们所使用的Linux中出现的1024部分存在于：\n  CFS调度算法中nice值是0的进程的权重;\n  CPU CGroup一般的初始权重;\n  ext4文件系统的block size可以是1024;\n  普通用户不能用1024以下的网络端口。\n  真实的程序员  在1842年，人称“数字女王”的阿达•洛芙莱斯(Ada Lovelace)编写了历史上首款电脑程序。在1834年，阿达的朋友——英国数学家、发明家兼机械工程师查尔斯•巴贝其(Charles Babbage)发明了一台分析机，阿达则致力于为该分析机编写算法，并于1843 年公布了世界上第一套算法。巴贝其分析机后来被认为是最早期的计算机雏形，而阿达的算法则被认为是最早的计算机程序和软件。\n 从2014年起，在IT行业的自发组织下，每年10月24日都被定义为程序员节，以一个节日的形式，向通过coding改变世界、也以实际行动在浮躁的世界里固执地坚持自己对于知识、技术和创新追求的程序员们表示致敬。\n 程序员真的是对数字非常敏感的一个团体，运行程序的硬件进制都是以1024为基础的，1TB = 1024GB，1GB = 1024MB，1MB = 1024KB，同时1GB由于其谐音的原因，还被大家用作”一级棒“的缩写，并且1024对程序员来说，是一个非常常用的一个数字，1024是2的十次方，二进制计数的基本计量单位之一，也因为这，有一个小段子，”菜鸟认为1KB有1000个字节，大神认为1公里有1024米。“经常被拿来调侃程序员的眼中就认为1000 = 1024。\n程序员也属于是被网上迫害调侃次数频繁的一群人了，经常被大家认为加班严重、头发稀少易秃、标配格子衫加休闲牛仔裤、死板木讷、和对象因为互相忙过几天就忘了对方是谁，而且同样的，之前我曾多次被家里的亲戚和父母的同事们问，“你是不是会修电脑啊”，”这些电脑的配置该怎么选啊“，“这手机用用就会很卡，你能修修么”，“我家网速很卡，你知道怎么能让网速快点么”，诸如以上问题。。。我想说的是程序员虽然或多或少会知道一些这类问题如何去解决，但是他们的工作并不是这样，而且真实的程序员也绝对不是被大家经常调侃的那样子。\n 真实的程序员，是一群善于学习、有创造力的人。他们会在新技术、新架构、新知识的产生时抱有很大的好奇心，不管自己感不感兴趣都会去或多或少的了解一下，在这个发展非常快速，更新迭代频繁的互联网行业中，程序员只有通过不断地学习才能立于不败之地。对于程序员集体，他们之间的对话有时候都是通过代码来表达，大家的沟通有时候都是在互相学习彼此的代码。\n而且由于一些人的强迫症或者是对代码的优化，有时候会对一个算法、一个架构、整体的格式进行几天的重新规整和修改，所以程序员们也是一群细心认真的人。程序员在工作和学习中最大的快乐无异于解决了一个庞大代码量中bug，那种心情和小孩吃到糖果一样开心到单纯。而程序员也绝不是很死板的人，他们有时候甚至会自己调侃自己，说一些笑话，比如：\n“女神：你能让这个办公室的人都吵起来，我今晚就跟你走。\n程序猿：Java语言是世界上最好的语言!\n本来安静的办公室突然一下炸锅了，各种吵架声此起彼伏。\n女神：服了你了，我们走吧，你想干啥都行。\n程序猿挽起袖子站到了椅子上：今天不行，我一定要说服他们，Java才是最好的语言。”\n所以程序员们本身都是比较好玩、搞笑的一群人，在应聘中必备词汇：了解=听过名字;熟悉=知道是啥;熟练=用过;精通=做过东西，而且最讨厌的是写注释、写文档、别人不写注释、别人不写文档……\n属于程序员们的1024  “这是一群主张用代码改变世界的人”\n 现在的生活愈发智能化，这背后都离不开程序员的功劳，无论是从事开发还是其他方向、领域的，只要是一名Coder，我们都是从一句 “Hello World!” 开始在这条路上共同进步。\n 最后，祝大家节日快乐。\n","date":"2021-10-24T00:00:00Z","image":"https://zonzeeli.github.io/p/1024/background_hu01306e7f7187c8613b2d59c7dfccc681_490149_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/1024/","title":"属于程序员们的1024🎉"},{"content":"Group By概述  顾名思义，Group By是将数据分组，将具有相同数据的行放在同一组中，使用Group By我们能对表的数据在可视化的基础上更加清晰的观察同类别、相同值的数据组。\n注：Group By是先经过排序后再分组。\nGroup By用法  首先最简单的Group By用法就是对单一的列进行分组，比如我想统计每个学校的学生人数：\n1 2 3  SELECTSchool,COUNT(*)AS`StudentNum`FROMMytableGROUPBYSchool;   利用School字段进行分组，然后统计每一组的行数，这样学生的人数就统计出来了。这里面要说一下Group By的一个语法注意事项，在Select中出现的字段，只能被包含在Group By语句中作为条件，或者是在聚合函数中使用。这一点很容易就被遗漏了，而且在不同的MySQL版本中会出现不一样的提示和报错。\n 首先表的内容如下，\n 然后执行如下语句会报错，如图：\n 这里的S1.Score，就没用被作为Group By的条件，所以不能使用，但是如果是下面这样，将两个字段都作为条件当作列就可以，或者是只用S1.score也是可以的，如图：\n 但是呢，之所以我这里强调一下这一点是因为，我在一些刷题网站或者其他地方的虚拟终端、控制台上敲代码的时候，发现有的人这样写的结果竟然没有问题，通过了，还可以作为某些问题的解法，这就让我产生了一些疑惑。首先看一下这段报错。\n1 2 3  ERROR 1055 (42000): Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column \u0026#39;test.S1.Score\u0026#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by    这段错误前半部分就是说明的就是Group By的那个语法要求，如果在Select中出现的列，没有在Group By中出现，或者是聚合函数中使用，那么这个SQL就不合法，但是后半部分this is incompatible with sql_mode=only_full_group_by，问题就在这里，我后来去查了一下，在MySQL 5.7.5版本之前only_full_group_by默认是不开启的，所以有个比较狠的方法就是改库。在命令行输入以下命令查看：\n1 2 3  mysql\u0026gt;SELECT@@GLOBAL.sql_mode;mysql\u0026gt;SELECT@@SESSION.sql_mode;   查询后如图：\n 会查询到only_full_group_by是开启的，所以把他关闭即可，输入如下命令：\n1 2  mysql\u0026gt;setglobalsql_mode=\u0026#39;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\u0026#39;;mysql\u0026gt;setsessionsql_mode=\u0026#39;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\u0026#39;;   之后就在MySQL 5.7.5之后的版本使用了。\nGroup By和Having的使用及子句执行顺序  这里首先介绍一下Where和Having的使用区别：\nWhere子句是在我们查询结果的执行分组前进行过滤，且条件不能使用聚合函数。\nHaving子句是在分组之后进行过滤，条件可以使用聚合函数。\n 所以我们能得到，正常的写法规则，Where要在Group By之前，而Having要在Group By之后，那么接下来就是完整的执行顺序：\n 先执行Where对行进行筛选，返回第1个结果集； 再执行Group By进行分组，返回第2个结果集； 执行Select，返回第3个结果集； 对结果集进行Having筛选，返回第4个结果集； 最后执行Order By进行排序   以上执行顺序，配合代码自己梳理一遍会更加的理解清晰。\n","date":"2021-09-23T00:00:00Z","image":"https://zonzeeli.github.io/p/sql-groupby/%E5%88%86%E7%BB%84%E8%83%8C%E6%99%AF_hu6567499104e8e7f68b4347d403819688_624669_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/sql-groupby/","title":"SQL——Group By的使用及子句执行顺序"},{"content":"堆(heap)  堆是一种常用的数据结构，其有两种性质：1.堆中某个节点的值总是不大于或不小于其父节点的值、2.堆总是一棵完全二叉树。堆有多种用法，类似于实现优先队列、堆排序、找最值等等，根据排序方式，堆又分为两种：最小堆(小根堆)、最大堆(大根堆)。最小堆，父节点的值不大于每一个子节点的值，同理可以推出最大堆，就是父节点都不小于每一个子节点的值。\n注：这里并不详细介绍堆的二叉树结构，树结构的相关基础知识有必要提前了解一下。\n堆排序  堆排序在TopK问题中是最常用的解题方法，堆排序是不稳定的，时间复杂度为$O(n\\log n)$，这里来分析一下堆排序，以最小堆/小根堆为例，假设我们给定一个nums数组[]int{0,15,6,10,8,4,9,3,12,7}，我们将这个数组以二叉树的结构表示出来，如下图：\n 堆排序的思想是从最后一个父节点开始，通过比较来更新父节点的值，然后在向下沉，即向下更新，我们可以知道父节点的索引为i，子节点的索引为2i+1和2i+2。最后一个父节点的索引为len(nums)/2-1。这里先放出下沉规则的代码，大家跟着代码来理解一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  func sink(nums []int, n int, i int) { //n为数组长度，i为当前父节点的索引  max := i l, r := 2*i+1, 2*i+2 //如果碰到子节点的值大于父节点，用子节点在中最大的值来替换  if l \u0026lt; n \u0026amp;\u0026amp; nums[l] \u0026gt; nums[max] { max = l } if r \u0026lt; n \u0026amp;\u0026amp; nums[r] \u0026gt; nums[max] { max = r } //把父节点换下去并向下调整  if max != i { nums[max], nums[i] = nums[i], nums[max] sink(nums, n, max) } }    接下来跟着图来走一遍下沉的思路，首先比较的是最后一个父节点，索引为4，子节点小于父节点的值，不需要更新。然后比较索引3，更换12和10的值，如图：\n 这里要注意，由于此处更换了父节点，所以要想下沉，自上而下对堆进行排序，要对索引8的子节点进行下沉操作，但是这里8处没有子节点了，所以无需向下沉。然后开始比较索引2，更换6和9的值，如图：\n 同样需要看一下是否需要向下沉，这里也不需要，接下来比较一下索引1的节点，索引1的节点父节点值都大于子节点，所以不需要替换。然后是索引0的节点，更换0和15的值，如图：\n 判断一下是否需要继续向下沉，发现对于父节点索引1需要重新进行下沉规则，更换0和12的值，如图：\n 更换值后，父节点索引为3同样需要继续下沉，再次更换0和10的值，如图：\n 此时，我们的已经创建好了堆，满足堆的属性，父节点都不小于子节点，而且堆的根节点是最大值。然后接下来要进行的是排序，把第一个值和最后一个值进行更换，这样子最大值就跑到了最后，最后一个值的顺序也就确定，再对前面的值进行上述操作，重新构建堆，如图：\n 再次进行上述的下沉规则，这时，最后应该把12和0进行位置更换，最后一个值为12，这样子12也是排序好了，然后再对之前的数进行上述操作，如图：\n 更换12和0，12也排序完成，对之前的数再次构建堆。\n 以此类推，我们最后就修改了原数组的顺序，结果返回为[]int{0,3,4,6,7,8,9,10,12,15}，这就是最小堆的堆排序，最后的根节点为最小值，所以也叫小根堆。下面是以最小堆为例的完整代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  func heapsort(nums []int, n int) { //创建堆，保证父节点和子节点之间的大小关系，遍历父节点 \tfor i := n/2 - 1; i \u0026gt;= 0; i-- { //创建过程中从最后一个父节点开始，向下沉 \tsink(nums, n, i) } //对堆进行排序，将第一个与最后一个值互换，省略对最后一个值的排序 \tfor i := n - 1; i \u0026gt; 0; i-- { nums[0], nums[i] = nums[i], nums[0] //排序过程从第一个开始，向下沉 \tsink(nums, i, 0) } } func sink(nums []int, n int, i int) { max := i l, r := 2*i+1, 2*i+2 //如果碰到子节点的值大于父节点，用子节点在中最大的值来替换 \tif l \u0026lt; n \u0026amp;\u0026amp; nums[l] \u0026gt; nums[max] { max = l } if r \u0026lt; n \u0026amp;\u0026amp; nums[r] \u0026gt; nums[max] { max = r } //把父节点换下去并向下调整 \tif max != i { nums[max], nums[i] = nums[i], nums[max] sink(nums, n, max) } }   go语言实现堆结构  go语言当中也有封装好的heap包可以使用，不过结构还是要自己来设定，以上面的数组为例，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  func main() { nums := []int{0, 15, 6, 10, 8, 4, 9, 3, 12, 7} test := \u0026amp;h{} heap.Init(test) for _, v := range nums { heap.Push(test, v) } //打印堆顶的元素 \tfmt.Println((*test)[0]) //Output: 0  for test.Len() \u0026gt; 0 { fmt.Printf(\u0026#34;%d \u0026#34;, heap.Pop(test)) } //Output: 0 3 4 6 7 8 9 10 12 15 } type h []int func (h *h) Len() int { return len(*h) } func (h *h) Less(i, j int) bool { return (*h)[i] \u0026lt; (*h)[j] } func (h *h) Swap(i, j int) { (*h)[i], (*h)[j] = (*h)[j], (*h)[i] } func (h *h) Push(v interface{}) { *h = append(*h, v.(int)) } func (h *h) Pop() interface{} { old := *h n := len(old) v := old[n-1] *h = old[0 : n-1] return v }    这里面应用到的就是container/heap这个包，go语言只是封装了一个堆，其他的需要定义的都由开发者自己去设定。可以点击进去查看一下这个heap包，其中有两个文件，example_intheap_test.go和example_pq_test.go，这两个文件就是堆和优先队列，官方给的例子文档，仿照这个来写就可以，这里解释一下。\n 首先看一下上述例子或者example_intheap_test.go中的代码，Len()和Swap()这两个函数很好理解，一个是返回数组的长度，一个是交换值，Less()函数这里是决定创建的堆是最小堆还是最大堆，即返回结果为真的顺序，上述例子中return h[i] \u0026lt; h[j]，即返回的是从小到大，也就是最小堆。而Pop()和Push()两个函数，分别是出堆顶元素和放进堆里元素，每次Pop()和Push()后，堆都会自动更新顺序，这也就是go语言为我们实现的。\n 那么有的人就疑惑了，这还要写这么多为什么不封装好呢？这里就是第二个例子，也就是example_pq_test.go中的优先队列，可以是用普通的线性结构来创造优先队列，但这里使用堆来创造会更简单。下面再举一个优先队列的例子，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  func main() { //要添加进队列的学生名单 \tlist := []Student{ {\u0026#34;James\u0026#34;, 18}, {\u0026#34;Karsa\u0026#34;, 16}, {\u0026#34;Bob\u0026#34;, 19}, } //已存在队列中的学生名单 \tpq := \u0026amp;PQ{ {\u0026#34;David\u0026#34;, 20}, } heap.Init(pq) for _, v := range list { heap.Push(pq, v) } fmt.Println((*pq)[0]) //Output: {Karsa 16} \tfor pq.Len() \u0026gt; 0 { fmt.Println(heap.Pop(pq)) } //Output: {Karsa 16} \t// {James 18} \t// {Bob 19} \t// {David 20} } type Student struct { Name string Age int } type PQ []Student func (pq *PQ) Len() int { return len(*pq) } //以年龄大小排序 func (pq *PQ) Less(i, j int) bool { return (*pq)[i].Age \u0026lt; (*pq)[j].Age } func (pq *PQ) Swap(i, j int) { (*pq)[i], (*pq)[j] = (*pq)[j], (*pq)[i] } func (pq *PQ) Push(v interface{}) { *pq = append(*pq, v.(Student)) } func (pq *PQ) Pop() interface{} { n := len(*pq) v := (*pq)[n-1] *pq = (*pq)[:n-1] return v }    上面这就是简易的优先队列的实现，其实相对于堆的数组就是用结构体中的某一个值来充当比较大小的值。另外，在example_pq_test.go代码中有个新的update()，顾名思义是用来修改优先队列中表示优先级的值的，需要额外给结构体添加一个表示索引的字段。\n 接下来我们看一下利用堆结构来做的算法题：\nLeetCode 347. 前 K 个高频元素 给你一个整数数组nums和一个整数K，请你返回其中出现频率前K高的元素。你可以按任意顺序返回答案。\n 这道题就很容易能想到用堆结构，结构体中带上数组中值和值出现的次数就可以，在Less()函数中用值出现的次数来做比较。然后最后出堆顶K次即可，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  func topKFrequent(nums []int, k int) []int { maps := make(map[int]int) for i := 0; i \u0026lt; len(nums); i++ { if _, ok := maps[nums[i]]; ok { maps[nums[i]]++ } else { maps[nums[i]] = 1 } } iheap := \u0026amp;Iheap{} heap.Init(iheap) for key, value := range maps { if iheap.Len() \u0026lt; k { heap.Push(iheap, [2]int{key, value}) } else { if (*iheap)[0][1] \u0026lt; value { heap.Pop(iheap) heap.Push(iheap, [2]int{key, value}) } } } res := make([]int, k) for i := 0; i \u0026lt; k; i++ { res[k-i-1] = heap.Pop(iheap).([2]int)[0] } return res } type Iheap [][2]int func (h Iheap) Len() int { return len(h) } func (h Iheap) Less(i, j int) bool { return h[i][1] \u0026lt; h[j][1] } func (h Iheap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *Iheap) Push(x interface{}) { *h = append(*h, x.([2]int)) } func (h *Iheap) Pop() interface{} { old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x }   LeetCode 264. 丑数 II 给你一个整数n，请你找出并返回第n个丑数。丑数就是只包含质因数2、3和或5的正整数。\n 首先先了解题意的丑数是什么意思，题干说了因数只包含2、3、5的正整数，所以其实就是2、3、5三个数互相乘积计算得到的数，并继续互相乘积，最后计算得到的就是丑数，比如如果x是丑数，那么2x、3x、5x也都是丑数。这道题也完全可以是用堆来做，用最小堆，首先将1加入堆中，1通常被视为丑数。每次堆顶都会是最小值，把乘法计数的值都存进堆中，需要一个hash来判断是否已经存过，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  type Heap []int func (h *Heap) Len() int { return len(*h) } func (h *Heap) Less(i, j int) bool { return (*h)[i] \u0026lt; (*h)[j] } func (h *Heap) Swap(i, j int) { (*h)[i], (*h)[j] = (*h)[j], (*h)[i] } func (h *Heap) Push(v interface{}) { *h = append(*h, v.(int)) } func (h *Heap) Pop() interface{} { v := (*h)[len(*h)-1] *h = (*h)[:len(*h)-1] return v } func nthUglyNumber(n int) int { var res int box := make(map[int]bool) var h Heap heap.Init(\u0026amp;h) heap.Push(\u0026amp;h, 1) for n \u0026gt; 0 { res = heap.Pop(\u0026amp;h).(int) fmt.Println(res) if !box[res*2] { box[res*2] = true heap.Push(\u0026amp;h, res*2) } if !box[res*3] { box[res*3] = true heap.Push(\u0026amp;h, res*3) } if !box[res*5] { box[res*5] = true heap.Push(\u0026amp;h, res*5) } n-- } return res }     堆和优先队列的结构使用场景非常多，而且也是解不少排序、个数题的方法，需要熟悉了解一下。另外也推荐提前把树的结构预习会对理解堆更有帮助。\n 这篇文章的结尾附上本人LeetCode主页： https://leetcode-cn.com/u/zonzeeli0523/\n","date":"2021-08-10T00:00:00Z","image":"https://zonzeeli.github.io/p/heap/heapbgi_huc5d87bcdba7a5bdb2d2f31e795ea4b08_530172_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/heap/","title":"数据结构与算法——堆结构"},{"content":"二分查找算法  二分查找算法又称为折半查找(Binary Search)，是查找算法中简单、快速、高效的查找算法。使用要求是有序排列，且是顺序存储结构。\n基本原理  我们用文字梳理一下二分查找的原理，假设给定一个无重复值的递增数组[ ]int，变量名为nums ：\n  如果序列本身为空，不会进入二分查找算法。\n  如果序列不为空，从首尾开始进行二分，分为left、right、mid，mid就是首尾折半，判断条件为left \u0026lt;= right。\n  判断target和mid的值大小：\n 如果此时nums[mid] == target，那么就找到了返回值，可以直接返回。 如果此时nums[mid] \u0026gt; target，那么说明返回值应该在当前索引mid的左侧，此时end = mid - 1，查找范围缩短。 如果此时nums[mid] \u0026lt; target，那么说明返回值应该在当前索引mid的右侧，此时start = mid + 1，查找范围缩短。    如果以代码来呈现的话就是这样。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  nums := []int{1, 2, 3, 4, 5, 6} target := 5 left, right := 0, len(nums)-1 var output int for left \u0026lt;= right { mid := (left + right) \u0026gt;\u0026gt; 1 if nums[mid] == target { output = mid break } else if nums[mid] \u0026gt; target { right = mid - 1 } else if nums[mid] \u0026lt; target { left = mid + 1 } }    上面介绍的就是最基本的二分查找模板，不过有时候也有很多的其他的情况，二分并没有什么具体的模板写法，不要一味的去套模板，很容易出现超时、找错索引的情况，一定要理解好了去使用。\n 但是这里面可能有人会有疑惑，为什么我看到其他人的写法在判断条件的for循环里是left \u0026lt; right？为什么有人的写法是left = mid，right = mid - 1或是left = mid + 1，right = mid？这些情况我们接着讨论。\n其他情况  我们修改一下原先的问题，带有重复数字的有序数组[]int，假设nums为{1,2,3,3,3,4}，如果我们按照上面的代码的话其实能找到3的位置，直接就能返回到第一个3的索引2为结果，但是如果我们想要找到最后一个3出现的位置该怎么办呢？这里面就存在了一个边界范围的情况讨论。这里我先以这道题为例，代码如下：\n1 2 3 4 5 6 7 8 9 10 11  nums := []int{1, 2, 3, 3, 3, 4} target := 3 left, right := 0, len(nums)-1 for left \u0026lt; right { mid := (left + right + 1) \u0026gt;\u0026gt; 1 if nums[mid] \u0026gt; target { right = mid - 1 } else { left = mid } }    这么一看是不是区别很大？但是却又和我们看到其他人写的二分法很像的样子。这样写比较好看，但同样也存在着问题，来分析和解释一下这段代码。\n 首先注意到了为什么这里面是left \u0026lt; right而不是left \u0026lt;= right，因为这道例子我们想要找的是右边界，所以搜索范围希望是一个从左到右，(left,right]，左开右闭的区间，这个搜索区间是和我们定义的right有关，如果你的right定义成了len-1，那就说明我们的搜索区间是[left,right]，如果是len就是[left,right)，因为nums(len)会越界。而这里的left \u0026lt; right在最后left == right时，可以让程序从[left,right)中正常终止，否则会陷入死循环。不过这个其实和下面left与right的值更新一起决定的。 接下来的mid := (left + right + 1) \u0026gt;\u0026gt; 1，这里的加1，是为了防止死锁，比如这道例子，假设我们的mid := (left + right) \u0026gt;\u0026gt; 1，在计算到left = 4，right = 5的时候，这是mid = 4，继续进入循环，进入循环后还是依然left = 4，right = 5，这样子就死锁了。 最后是判断条件和更新值的不一样，这道例子是找右边界的target，有这三种情况：  在nums[mid] \u0026gt; target的情况，说明mid肯定不是我们要找的索引，目标值应该在mid的左边，right范围可以直接减1，即right = mid - 1； 在nums[mid] = target的情况，这时候没办法说明mid是最右边的，但可以肯定的是，至少是在mid靠右的部分，所以此时该更新left = mid，而不是left = mid + 1我们保留当前的mid还在我们接下来的搜索范围内，这样子避免万一当前mid就是右边界从而导致找不到值； 在nums[mid] \u0026lt; target的情况，说明mid肯定不是我们要找的索引，目标值应该在mid的右边，有人会疑惑，那不该是left = mid + 1吗？不这么写是因为有一种情况，[2,2]，如果我们想找target = 3，因为所有的值都比目标值小，我们返回的left就会越界超出索引，这种情况是在此写法下会发生的问题。     另外大家思考一下，如果找的目标值不存在nums里我们返回的是什么呢？比如上面的代码中，如果我们的目标值是0的话，返回的是0，如果目标值是5的话，返回的是5。这里其实是返回小于目标值的最右边界索引。\n 到这可能很多人也懵了，那这么多情况该怎么处理好呢，感觉写起来很困难。\n思路  最开始我也在这地方卡了很久，可能是会做了一道题，再出另一道题就不会做了，一道题的二分法写法肯定不只是一种，这个是根据left和right的定义，还有判断规则来决定的，这个需要多总结。我个人认为二分的思路需要如下，以一道题为例：\nLeetcode 35. 搜索插入位置 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。请必须使用时间复杂度为$O(\\log n)$的算法。\n 首先我们先理清题意，这道题转换一下就是要找到目标值，返回其索引，如果不存在则找到大于目标值的最左边界，如果都小于目标值的话，那就返回len(nums)。 理清楚了这道题的是要找左边界，那么我们就先来思考判断条件，如果我们的nums[i] \u0026gt; target的话，那么我们的target可能是在[0，i]之间，这里之所以i也包含是因为，如果不存在目标值的话，i可能是大于目标值的最左边界，所以要保留该索引，或者这么思考，如果我们的nums[i] \u0026lt; target，那么i下的值肯定不是我们要找的值，搜索空间应该在i之后，所以应该是[i+1, ]。 在理清楚判断规则后，接下来就是left和right的定义了，这道题right定义成len(nums)-1，这个就像上面解析所说，是根据自己写法的定义，如果说是循环条件left \u0026lt;= right的话，那么我们的left和right都不能更新成mid，也就是left = mid + 1和right = mid - 1这种形式，因为防止进入死锁，没有办法终止，反之，如果left \u0026lt; right这样的条件，最后的结果就是left == right，可以终止循环。   按照上面的思路我们写出来该题的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  func searchInsert(nums []int, target int) int { if target \u0026gt; nums[len(nums)-1] { return len(nums) } left, right := 0, len(nums)-1 for left \u0026lt; right { mid := (left + right)/2 if nums[mid] \u0026lt; target { left = mid + 1 }else { right = mid //这里的条件left \u0026lt; right可以防止死循环  } } return left }    那如果循环条件是left \u0026lt;= right的代码应该是这样:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  func searchInsert(nums []int, target int) int { if target \u0026gt; nums[len(nums)-1] { return len(nums) } left, right := 0, len(nums)-1 for left \u0026lt;= right { mid := (left + right)/2 if nums[mid] \u0026lt; target { left = mid + 1 }else { right = mid - 1 } } return left }    到这里，是否对二分法熟悉了很多，那么再来看一道例题:\nLeetcode 34. 在排序数组中查找元素的第一个和最后一个位置  注：该题与 剑指Offer 53 - I. 在排序数组中查找数字Ⅰ 题干一样，只是返回要求不同。\n给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。如果数组中不存在目标值 target，返回[-1, -1]。 进阶：你可以设计并实现时间复杂度为$O(\\log n)$的算法解决此问题吗？\n 首先看这道题我们就清楚了是要找到目标值的最左和最右边界题，而且题干给了题意是$O(\\log n)$的算法，这就说明要使用二分法来做了，这个要记住，不少题会这么说，这也是二分法的时间复杂度，很有标志性。 然后我们首先要知道，如果数组的长度是0，或者目标值大于数组最大的值，或者小于数组最小的值，那么就可以直接返回要求的[-1. -1]。 接下来就是两步二分法，分别找左右边界，第一个二分法找左边界，我们定义left和right分别是0和len(nums)-1，循环条件为left \u0026lt; right，找左边界的化，如果是nums[mid] \u0026lt; target，这种情况说明当前mid下的值肯定不是我们所要找的值，搜索范围应该[mid + 1, ]，所以left = mid + 1，或者思考，如果是nums[mid] \u0026gt;= target，在等于的情况下好说，可能是最左边界，但是要继续向左找，所以保留mid，在大于的情况下，一是因为循环条件的设定，另一个是因为为了找左边界，如果没有目标值的话，会返回大于目标值的最左边界，令right = mid。最后我们返回，start = left。 那么接下来就是找右边界了，定义和循环条件还是不变，如果nums[mid] \u0026gt; target，这说明了当前值过大了，那么我们要找的范围就是从[0, mid - 1]，所以此时缩小范围，令right = mid - 1，反之，如果是nums[mid] \u0026lt;= target，在等于的情况下很好理解，该值可能是最右边界，所以保留继续向右搜索，如果是小于的情况下，考虑到如果没有目标值，则返回小于目标值的最右边界，所以此时令left = mid。最后我们返回end = left。 最后就是如果真的没有目标值，那就是左边界的索引大于右边界的索引，即start \u0026gt; left。   按照上面的思路我们写出来该题的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  func searchRange(nums []int, target int) []int { if len(nums) == 0 || target \u0026gt; nums[len(nums)-1] || target \u0026lt; nums[0] { return []int{-1,-1} } start, end := 0, 0 left, right := 0, len(nums)-1 for left \u0026lt; right { mid := (left+right) \u0026gt;\u0026gt; 1 if nums[mid] \u0026lt; target { left = mid + 1 }else { right = mid } } start = left left, right = 0, len(nums)-1 for left \u0026lt; right { mid := (left+right+1) \u0026gt;\u0026gt; 1 if nums[mid] \u0026gt; target { right = mid - 1 }else { left = mid } } end = left if start \u0026gt; end { return []int{-1, -1} } return []int{start, end} }    如果能理解到这，或者这两道题可以做出来了那至少正常的二分法是了解差不多了，接下来再举两道同类型的，我认为比较有代表性的二分法题：\nLeetcode 153. 寻找旋转排序数组中的最小值 已知一个长度为 n 的数组，预先按照升序排列，经由 1 到 n 次 旋转 后，得到输入数组。例如，原数组 nums = [0,1,2,4,5,6,7] 在变化后可能得到： 若旋转 4 次，则可以得到[4,5,6,7,0,1,2] 若旋转 7 次，则可以得到[0,1,2,4,5,6,7] 注意，数组[a[0], a[1], a[2], ..., a[n-1]]旋转一次 的结果为数组[a[n-1], a[0], a[1], a[2], ..., a[n-2]]。\n给你一个元素值 互不相同 的数组 nums ，它原来是一个升序排列的数组，并按上述情形进行了多次旋转。请你找出并返回数组中的 最小元素 。\n 首先我们要思考的问题是，这道题为什么可以用二分法？二分法的要求不是有序吗？确实是这样我们来分析一下这道题，这道题相当于是两段有序的数组，且第二段的末尾接着第一段的首。我们可以思考一下情况：  如果是没有进行旋转，那么可以正常使用二分，此时nums[mid] \u0026gt; nums[left]，且nums[mid] \u0026lt; nums[right]，即正常的顺序，这样最小值一定在mid的左边范围 如果是nums[mid] \u0026lt; nums[left]，且nums[mid] \u0026lt; nums[right]，即中间值小于两边值，这说明肯定旋转过，最小值一定在包含mid的左边范围。 如果是nums[mid] \u0026gt; nums[left]，且nums[mid] \u0026gt; nums[right]，即中间值大于两边值，这也说明肯定旋转过，最小值一定在mid的右边范围。 最后一种情况是nums[mid] \u0026lt; nums[left]，且nums[mid] \u0026gt; nums[right]，这种情况不会发生。   经过上面的分析我们可以看出来，通过比较nums[mid]与nums[right]的大小就能找出来接下来的搜索范围。所以这道题二分法是可行的。   按照上面的思路我们写出来该题的代码:\n1 2 3 4 5 6 7 8 9 10 11 12  func findMin(nums []int) int { left, right, mid := 0, len(nums)-1, 0 for left \u0026lt; right { mid = (left + right) \u0026gt;\u0026gt; 1 if nums[mid] \u0026gt; nums[right] { left = mid + 1 }else { right = mid } } return nums[left] }   Leetcode 154. 寻找旋转排序数组中的最小值 II 已知一个长度为 n 的数组，预先按照升序排列，经由 1 到 n 次 旋转 后，得到输入数组。例如，原数组 nums = [0,1,4,4,5,6,7] 在变化后可能得到： 若旋转 4 次，则可以得到 [4,5,6,7,0,1,4] 若旋转 7 次，则可以得到 [0,1,4,4,5,6,7] 注意，数组 [a[0], a[1], a[2], ..., a[n-1]] 旋转一次 的结果为数组 [a[n-1], a[0], a[1], a[2], ..., a[n-2]] 。\n给你一个可能存在 重复 元素值的数组 nums ，它原来是一个升序排列的数组，并按上述情形进行了多次旋转。请你找出并返回数组中的 最小元素 。\n 理清了上面的那道题我们就对这道题的思路很清晰了，比较nums[mid]与nums[right]的值就可以，但是这道题为什么会成为困难题？因为这里包含了重复元素，如果是重复元素的话，我们上面的解法就会出现错误。但是真的不可以那么做了吗？ 我们可以举一个非常简单的例子看一下区别，上面的例子，是因为我们可以通过比较nums[mid]与nums[right]的值，可以判断该往哪个方向收缩搜索范围，而这道题，如果是[1,0,1,1]和[1,1,0,1]，唯独在nums[mid] == nums[right]的情况下，我们没有办法判断该往哪个方向收缩。所以这道题需要做的就是在相等的情况下如何去处理。这里的处理方式是在nums[mid] == nums[right]的情况下，令right = right - 1。正常来理解就是直到把这个重复的数字删去让nums[mid]与nums[right]的判断不受到影响就可以。 那么条件是否允许呢？有两种情况，nums[right]是我们要找的最小值，且如果不是唯一的话，nums[mid]会依然在我们的搜索范围内，如果是唯一的话，那么此时nums[mid] == nums[right]，可以推出mid == right，但是因为是向下取整的，mid可能等于left不会等于right。   按照上面的思路我们写出来该题的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  func findMin(nums []int) int { left, mid, right := 0, 0, len(nums)-1 for left \u0026lt; right { mid = (left + right) \u0026gt;\u0026gt; 1 if nums[mid] \u0026gt; nums[right] { left = mid + 1 }else if nums[mid] \u0026lt; nums[right] { right = mid }else if nums[mid] == nums[right] { right -- } } return nums[left] }     二分算法的解析和例题题解就到这，如果这几道题能理解清楚的话，二分法基本没啥问题，不过还是要多加练习，刷刷LeetCode上面的题。\n 这篇文章的结尾附上本人LeetCode主页： https://leetcode-cn.com/u/zonzeeli0523/\n","date":"2021-08-02T00:00:00Z","image":"https://zonzeeli.github.io/p/binary-search/bsbgi_hu99e8ca8a10a73e12803b3da53a0f1e24_400965_120x120_fill_box_smart1_3.png","permalink":"https://zonzeeli.github.io/p/binary-search/","title":"数据结构与算法——二分查找"},{"content":"前言  你是否在面对任务、需求的时候考虑过复杂繁琐的单体应用？单体应用无论是逻辑梳理、排查问题和内容划分等各方面都会花费很多的时间和人力。在云计算快速发展的现在，微服务架构是业界开发应用的主要方式，尤其是现在正处于云原生的时代，微服务对运维、开发人员的工作相对变得容易。\n 但是微服务真的就完美了么？当然不是。单体应用的数据库、运维部署、技术开发等模块都是紧密联系在一起的，有时候一个功能需求写个超级长的代码负责给一个人也是能够解决的。而微服务就是从单体应用转变成了好多个，这样子在运维方面就变得复杂，不仅如此，以往的模块间属于进程间通信，微服务就只能使用RPC通讯方式。在这种情况下，Service Mesh出现了，有人提出Service Mesh是下一代微服务的基础。\n什么是Service Mesh？  “A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.” ————Willian Morgan (Buoyant CEO)\n 上面的这段话是Service Mesh的创造者给出的定义。这段英文中有几处关键的地方，如 “service-to-service communication ”、“reliable delivery of requests”、“cloud native application”、“lightweight network proxies”。总结来讲，Service Mesh是用来处理服务之间通讯连接，并且实现可靠的请求发送的轻量级网络代理，这些网络代理一定是跟应用部署在一起，但对应用透明。\n 如果说云原生时代下的DevOps与容器化可以解决庞大的构建部署问题，实现自动化管理。那么Service Mesh就如定义说的一样，解决了服务之间的通信问题，让服务在非进程间也变得紧密，通信更加容易。\nService Mesh的起源与发展  对于微服务引用的问题，类似于Spring Cloud、gRPC等框架解决了分布式的一些通信问题，关键是简化了开发，所以在微服务时代下发展的很快，但是同样如果去掌握、理解框架本身是一件难事，而且尽管梳理清晰了，业务逻辑和通信部分融合在一起，也会出现问题，更何况有时候甚至出现兼容性问题。另外就是支持的语言，gRPC框架支持了跨语言间的通信服务连接，但是有多少个语言就需要多少个类库，而且没有支持的就很难接入微服务，这对于整个架构来讲也是一个痛点。\n 最开始的应用在Linkerd上的Service Mesh是边车模式(Sidecar)，客户端应用实例会请求发送到本地的Service Mesh实例上，上面说的是非进程间通信，所以这两个是独立的进程，Service Mesh同样会实现负载均衡(Load Balancing)、服务发现(Service Discovery)、服务熔断(Circuit Breaker)和安全通讯等，还会负责动态路由、容错限流、监控日志等，其实说白了就是通过一个代理，实现了通信，完成了服务之间的通信请求。而Service Mesh就正如翻译的那样，通过这些代理连接形成网格实现连接。正如下面的图片一样，绿色代表的是应用，蓝色就是代理。\n 之后出现了Envoy，Envoy是一种高性能C++分布式代理，也是边车模式，任务是完成请求发送，解决通信问题，Envoy其实可以效仿一下网络模型的流程思路，采用监听端口Listener，然后可以对网络请求的数据进行处理、添加、校验等等，根据源数据层次不同，可以分为L3、L4、L7层，请求发出去到后端后，又根据集群模式进行负载均衡等等，另外Envoy可以支持根据路由规则发送给Cluster，在HTTP /1和HTTP /2之间是透明的。\n 直到Istio的出现，译义为“起航”，它的logo也是一个帆船，这个是Service Mesh最火热的框架，引入了一个集中式的控制平面，官方给出的架构图，也是为了数据和控制两块，数据利用Envoy代理组件，处理分布式系统的网络问题，而控制平面由Pilot、Mixer、Citadel和Galley四个组件负责。Istio不仅提供了关键功能如流量控制、面板观察、安全验证等，还有提供了高集成和定制，但目前还只是对Kubernetes友好。\n真的需要Service Mesh吗？  就我个人的粗略看法，毕竟没有深入那么多，只是在表层了解了一下，我认为还是很需要Service Mesh。它更大程度的简化了通信、远程调用的方式，而且几乎所有语言支持，这样子对任何一个开发人员都很友好。在一个业务开发团队中，或者说大一点到一个公司的应用服务体系，有时候一个关键、方便的架构有利于业务的实现，减少业务压力，这就好比一个程序员把自己写好的一个库、函数、脚本封装起来为了更简单的调用一样，一切都是想要在目前复杂且庞大的现代化软件系统中简化，让如此多人数协作起来更方便。\n 注：以上的具体技术内容感兴趣建议深入了解，这里表达浅显。\n","date":"2021-07-25T00:00:00Z","image":"https://zonzeeli.github.io/p/service-mesh/ServiceMesh%E8%83%8C%E6%99%AF%E5%9B%BE_hu2828ace76be6fa70103c605a45f3b754_547688_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/service-mesh/","title":"浅析微服务之Service Mesh"},{"content":"搭建博客流程  首先如果是正常的搭建博客，是需要写一个博客的后端和前端界面的，然后需要代理服务器或者云服务器去进行部署，再去购买一个域名作为你网站的标识，这样子就是动态的，其实就是程序在跑，这种并不太适合非程序员的小伙伴来做，而且后端部分的代码的复杂程度还要根据你的功能需求来决定，感兴趣的人可以尝试尝试，这一套流程搞定了整个后端开发也就熟悉不少了。\nhugo框架  hugo是一个基于go语言开发的个人博客框架，相对于之前和热门的hexo来说更简单操作，也同样是使用markdown来个编辑文章内容，这里将介绍一下如何使用hugo来搭建个人的博客网站。\n本地预览 一、安装hugo  如果你是mac系统的话，mac系统直接使用brew来安装就可以了。如果是windows，可以 点击此处 去github直接下载，可以选择适合你系统的版本进行下载，下载下来是一个指令，windows记得要添加环境变量。\n1  % brew install hugo    然后通过hugo version来查看是否安装成功和你的hugo版本。\n1  % hugo version    如果是上图的样子就说明已经是安装成功了。接下来需要新建一个站点，是我们整个blog存放的位置。\n1  % hugo new site blog   二、渲染博客网站主题  我们cd blog，之后的操作都在这个目录下，通过ls -l查看一下我们新建的这个站点里面初始都有些什么文件。\n 接下来就是需要给博客网站一个主题，我们可以 点击此处 去官方网站下载自己喜欢的主题，直接拿来用。点进去一般都有安装教程，用git clone将主题下载到我们本地/themes里，如果git clone不行的话，可以去主题的github仓库，下载zip文件，解析后放在当前目录的/themes文件下，直观一些看就是这样。\n 我们下载下来的主题都会提供一个example或是/exampleSite这样的文件夹，可以看该主题的默认介绍和展示效果，亦或者可以在hugo主题官方上看到他的demo，这里我们就在本地查看一下。这里我下载了minima这个主题来举例子，首先我们把当前目录的config.toml名字先改了，我改成config_orginal.toml，然后把我们下载下来的文件里的/exampleSite所有内容复制下来，粘贴在当前目录，(有的还需要复制/archetyoes下的文件，具体看是否有多余的内容)，而且还要查看一下config.toml这个文件里disqusShortname的值，然后修改我们下载下来的主题文件名为这个值，最终效果如下：\n三、本地运行博客网站  接着我们就可以用hugo server -t hugo-minima --buildDrafts来在本地预览我们的博客网站了，命令里的hugo-minima是刚才我们修改过的主题文件名。\n1  % hugo server -t hugo-minima --buildDrafts    当界面如下面这样子，就说明已经在本地运行成功了。\n 我们打开浏览器，在输入localhost:1313或者127.0.0.1:1313查看我们的博客预览界面。想要具体修改和发布我们的文章呢就在/content文件下添加修改.md文件就可以了，其他的一些配置和功能可以在当前目录下的config.toml和主题文件下下的/layouts中的.html文件修改。\n部署github  只单单在本地预览肯定是不够的，我们需要一个服务器可以部署我们的网站，这里github提供了很方便的部署方法。首先在我们自己的github账号下新建仓库New repository，这里要注意的是Repository name,这个取名必须是你自己的github名称，还需要全部小写，然后加上后缀，比如我这里就是zonzeeli.github.io。\n 创建好之后接下来的操作就是基本的git操作了，这个不熟悉的同学可以去了解一下基本的步骤就可以，并不是很难，这里也简单介绍一下，另外要注意提前把config.toml配置文件中的baseUrl修改成如命令行中一样的地址。\n1  % hugo --theme=hugo-minima --baseUrl=\u0026#34;https://zonzeeli.github.io\u0026#34;    这个命令操作后，会在当前目录下生成一个/public文件，这时候我们就要进入该目录cd public，然后执行git init。\n 接着就在这个/public目录下，git add .，git commit -m \u0026quot;myblog init\u0026quot;，git remote add origin https://github.com/ZonzeeLi/zonzeeli.github.io.git ，上面这条命令会要求输入github的账号和密码，最后在git push -u origin master这一步推流到github上。其中\u0026quot;myblog init\u0026quot;可以自定，原地址也填自己仓库的https地址。下面是git具体输入过的git命令。\n 这一切操作完我们就将博客部署到了github上了，直接输入我们之前的baseURL就可以进入到我们的博客了。\n","date":"2021-03-27T00:00:00Z","image":"https://zonzeeli.github.io/p/make-blog/hugo%E6%90%AD%E5%BB%BA%E8%83%8C%E6%99%AF_huac03c657a20a69ee78e6049e06cdcf8b_318623_120x120_fill_box_smart1_3.png","permalink":"https://zonzeeli.github.io/p/make-blog/","title":"搭建个人博客网站——hugo"},{"content":"定义 所谓的时间复杂度，是一种用来对程序运行时间评估描述的函数。表示的方式一般都是大O()符号，在输入值不同，时间的变化范围也不同，所以可以称为渐近的。我们平常所使用的都是最坏情况复杂度，即输入取任意值得到的最大运行时间，记为T(n)。当然还有最好情况和平均情况，不过较少使用，也是在具体情况下用来评估。\n如何计算时间复杂度 时间复杂度的计算方法统称来讲是大O推导法，从代码的执行次数上开始分析，比如如果一个代码的执行次数是常数量，并不随着我们的输入变化而变化，那么时间复杂度就是O(1)，反之，如果和输入n有关就需要进行分析，看下面代码例子：\n1 2 3  for i := 0;i \u0026lt; n;i ++ { // 1  fmt.Println(\u0026#34;Hello Go!\u0026#34;) // 2 }   这段代码就是执行了n+1次1行，执行了n次2行，所以是2n+1次，即T(n)=2n+1，时间复杂度就是O(n)。这里就有我们刚才提到的大O推导法，推导法的规则可以分为：\n 当n逐渐增大趋于无穷，常数量可以忽略不计，比如T(n)=n+1000，时间复杂度为O(n)。 大O的表示可以忽略系数，阶数与n对时间的变化影响更大，比如T(n)=2$n^2$+3，时间复杂度为O($n^2$) 忽略低阶，使用高阶作为时间复杂度，高阶的影响更大，比如T(n)=3$n^3$+2$n^2$+3,时间复杂度为O($n^3$) 在顺序执行或者条件判断等类似情况下，选择其中时间复杂度最大的作为整体的时间复杂度，比如下面的代码：  1 2 3 4 5 6 7 8  for i := 0; i \u0026lt; m; i++ { for j := 0; j \u0026lt; n; j++ { fmt.Println(\u0026#34;时间复杂度为O(mn)\u0026#34;) } } for i := 0; i \u0026lt; n; i++ { fmt.Println(\u0026#34;时间复杂度为O(n)\u0026#34;) }   这里的时间复杂度就是O(mn)，条件判断的处理方式也同理，所以比较简单的时间复杂度的计算方式就是这样子，那么看一下下面这段代码的时间复杂度：\n1 2 3 4  for i := 1;i \u0026lt; n;i ++ { i *= 2 fmt.Println(i) }   这段代码首先我们能看出来是和n有关系的，但是真的是执行了n次吗？因为i *= 2这个条件的在，让原先的执行次数缩小了很多，由$2^c$=n，推出c=$\\log_2 n$，但是这里的2，可以是3、4\u0026hellip;任何数，所以这个时间复杂度表示为O($\\log n$)，再举一个经典递归，斐波那契数列的例子：\n1 2 3 4 5 6 7  func example(n int) int { if n \u0026lt;= 1 { return 1 } else { return example(n-1) + example(n-2) } }   这是著名的斐波那契数列问题，也是经典的递归问题，这道题输入正整数，如果n是1的话，就执行一次，但是如果输入一个未知的n的话，执行的就是$2^0$+$2^1$+$2^2$+\u0026hellip;+$2^n$，所以时间复杂度为O($2^n$)。\n常见的时间复杂度 首先时间复杂度有一个优劣对比，即\nO(1) \u0026lt; O($\\log n$) \u0026lt; O(n) \u0026lt; O($n\\log n$) \u0026lt; O($n^2$) \u0026lt; O($n^3$) \u0026lt; O($2^n$) \u0026lt; O($n!$) \u0026lt; O($n^n$)，\n我们多数情况下在对比时间复杂度是排序算法和查找算法。下面是常见的几种算法的时间复杂度：\n   排序算法 最差情况 平均情况 空间复杂度 稳定性     冒泡排序 O($n^2$) O($n^2$) O(1) 稳定   选择排序 O($n^2$) O($n^2$) O(1) 不稳定   快速排序 O($n^2$) O($n\\log n$) 平均O($\\log n$)，最差O($n^2$) 不稳定   二叉树排序 O($n^2$) O($\\log n$) O(n) 稳定   堆排序 O($n\\log n$) O($n\\log n$) O(1) 不稳定   插入排序 O($n^2$) O($n^2$) O(1) 稳定       查找算法 平均情况 条件     顺序查找 O(n) 无   二分查找 O($\\log n$) 有序   二叉查找树 O($\\log n$) 左右字数均为二叉查找树，且中序遍历递增   哈希查找 O(1) 建立好哈希map，也因此空间复杂度较高    注：排序算法的稳定性指的是值相等的元素的前后顺序经过排序算法后是否会改变。\n常见的时间复杂度处理的数据规模 如果你经常刷LeetCode，会看到题干和样例下面有提供一些数据规模，这里的数据规模其实就限制或者说告诉你可以用怎么样的时间复杂度进行计算，不然每次都用暴力解，很多题是会超时的，下面是几个常见的时间复杂度大致对应的数据规模：\n   时间复杂度 数据规模     O($\\log n$) 很大   O($n$) $10^6$~$10^7$   O($n\\log n$) $5*10^5$   O($n^2$) $10^3$~$5*10^3$   O($n^3$) 200~500   O($2^n$) 20~24   O($n!$) 9~12    ","date":"2020-12-24T00:00:00Z","image":"https://zonzeeli.github.io/p/time-complexity/backgroud_hu657e1541751ab3fe88efa1500cb20dad_556714_120x120_fill_q75_box_smart1.jpg","permalink":"https://zonzeeli.github.io/p/time-complexity/","title":"数据结构与算法——时间复杂度"}]